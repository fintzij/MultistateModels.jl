# =============================================================================
# Implicit Differentiation for PIJCV Smoothing Parameter Selection
# =============================================================================
#
# Implements ImplicitDifferentiation.jl integration for efficient gradient 
# computation during PIJCV-based smoothing parameter selection.
#
# MATHEMATICAL FOUNDATION:
# The PIJCV criterion V(Ï) depends on Î²Ì‚(Ï) which is defined implicitly as:
#   Î²Ì‚(Ï) = argmin_Î² [-â„“(Î²) + Â½ Î£â±¼ Î»â±¼ Î²áµ€Sâ±¼Î²]  where Î» = exp(Ï)
#
# At the optimum, the first-order conditions hold:
#   c(Ï, Î²Ì‚) = âˆ‡_Î² â„“(Î²Ì‚) - Î£â±¼ Î»â±¼ Sâ±¼ Î²Ì‚ = 0
#
# By the implicit function theorem:
#   âˆ‚Î²Ì‚/âˆ‚Ïâ±¼ = -H_Î»â»Â¹ Â· (Î»â±¼ Sâ±¼ Î²Ì‚)
#
# where H_Î» = -âˆ‡Â²â„“(Î²Ì‚) + Î£â±¼ Î»â±¼ Sâ±¼ is the penalized Hessian.
#
# This avoids nested AD and reduces complexity from O(npÂ³) to O(npÂ²).
#
# REFERENCES:
# - Wood, S.N. (2024). "On Neighbourhood Cross Validation." arXiv:2404.16490v4
# - Blondel et al. (2022). "Efficient and Modular Implicit Differentiation."
#
# =============================================================================

using ImplicitDifferentiation
using ImplicitDifferentiation: MatrixRepresentation, DirectLinearSolver
using ADTypes: AutoForwardDiff

# =============================================================================
# Robust Linear Solve for Leave-One-Out Hessians
# =============================================================================

"""
    solve_hloo(H_loo::AbstractMatrix, b::AbstractVector; 
               damping_init::Float64=1e-8,
               damping_max::Float64=1e-2,
               verbose::Bool=false) -> Vector{Float64}

Robustly solve H_loo * x = b for leave-one-out Hessian systems.

Uses progressive damping with Cholesky factorization for efficiency and
numerical stability. Falls back to general solver if Cholesky fails.

# Algorithm
1. Symmetrize H_loo (in case of numerical asymmetry)
2. Try Cholesky with increasing damping: Ï„ âˆˆ [0, 1e-8, 1e-7, 1e-6, 1e-2]
3. If all fail, fall back to general `\\` solver
4. If that fails too, return NaN vector

# Arguments
- `H_loo`: Leave-one-out Hessian matrix H_{Î»,-i} = H_Î» - Háµ¢
- `b`: Right-hand side vector

# Keyword Arguments
- `damping_init::Float64=1e-8`: Initial damping value for Tikhonov regularization
- `damping_max::Float64=1e-2`: Maximum damping before giving up on Cholesky
- `verbose::Bool=false`: Print diagnostic messages

# Returns
Solution vector x, or vector of NaN if solve fails completely.

# Notes
- Damping adds Ï„I to the matrix, improving conditioning: (H + Ï„I)x = b
- This is equivalent to Tikhonov regularization in the Newton step
- The small damping values (1e-8 to 1e-2) have minimal effect on the solution
  when the matrix is well-conditioned, but stabilize ill-conditioned cases
"""
function solve_hloo(H_loo::AbstractMatrix, b::AbstractVector;
                    damping_init::Float64 = 1e-8,
                    damping_max::Float64 = 1e-2,
                    verbose::Bool = false)
    n = length(b)
    
    # Symmetrize to handle numerical asymmetry
    H_sym = Symmetric(0.5 * (H_loo + H_loo'))
    
    # Progressive damping schedule
    damping_values = [0.0, damping_init, damping_init * 10, damping_init * 100, damping_max]
    
    for Ï„ in damping_values
        try
            H_damped = Ï„ > 0 ? H_sym + Ï„ * I : H_sym
            fact = cholesky(H_damped)
            x = fact \ b
            verbose && Ï„ > 0 && @info "solve_hloo: used damping Ï„=$Ï„"
            return x
        catch e
            # Continue to next damping value
            continue
        end
    end
    
    # Fall back to general solver (handles indefinite matrices)
    try
        verbose && @warn "solve_hloo: Cholesky failed with all damping values, using general solver"
        return H_sym \ b
    catch e
        verbose && @error "solve_hloo: All solvers failed" exception=e
        return fill(NaN, n)
    end
end

# =============================================================================
# Barrier-Augmented LOO Solve (Phase 7)
# =============================================================================

"""
    solve_hloo_barrier(H_loo, g, lb, beta; Î¼=1e-6) -> NamedTuple

Compute barrier-augmented LOO Newton step that respects lower bounds.

# Mathematical Formulation

Instead of solving Hâ»Â¹g directly (which may violate Î² â‰¥ L), we solve:

    Î” = (H + Î¼Dâ»Â²)â»Â¹ (g + Î¼Dâ»Â¹ğŸ™)

where D = diag(Î² - L + âˆšÎ¼) is the regularized distance to lower bounds.

This is equivalent to a single Newton step on the barrier-augmented problem:
    min Â½(Î²-Î²Ì‚)áµ€H(Î²-Î²Ì‚) + gáµ€(Î²-Î²Ì‚) - Î¼Î£â‚–log(Î²â‚– - Lâ‚–)

# Arguments
- `H_loo`: Leave-one-out Hessian H_{Î»,-i} (p Ã— p matrix)
- `g`: Subject gradient gáµ¢ (p-vector, loss convention: g = -âˆ‡â„“)
- `lb`: Lower bounds L (p-vector)
- `beta`: Current parameter estimate Î²Ì‚ (p-vector)

# Keyword Arguments
- `Î¼::Float64=1e-6`: Barrier strength. Offset is âˆšÎ¼ â‰ˆ 0.001.
  At bound: Hessian contribution = Î¼/(âˆšÎ¼)Â² = 1 (well-scaled).
  Interior: negligible when Î´ >> âˆšÎ¼.

# Returns
NamedTuple with fields:
- `Î”`: Barrier-augmented Newton step (p-vector)
- `d`: Regularized distances d = Î² - L + âˆšÎ¼ (for gradient computation)
- `D_inv`: 1/d element-wise
- `D_inv_sq`: 1/dÂ² element-wise  
- `A_fact`: Factorization of augmented Hessian (for reuse in gradient)

# Notes
- Uses offset âˆšÎ¼ (not Îµ=1e-10) so barrier Hessian is O(1) at bounds, not O(10^14)
- For well-interior parameters (Î´ >> âˆšÎ¼), this matches solve_hloo to O(Î¼/Î´Â²)
- Near-boundary parameters get barrier push-back proportional to constraint tightness
- Always returns finite values (no NaN from bound violations)

# Reference
Novel extension of Wood (2024) "On Neighbourhood Cross Validation" Section 4.1
"""
function solve_hloo_barrier(
    H_loo::AbstractMatrix,
    g::AbstractVector,
    lb::AbstractVector,
    beta::AbstractVector;
    Î¼::Float64 = 1e-6
)
    n = length(beta)
    
    # Regularized distance to lower bounds: D = Î² - L + âˆšÎ¼
    # Using âˆšÎ¼ (not tiny Îµ) ensures barrier Hessian is O(1) at bounds
    sqrt_Î¼ = sqrt(Î¼)
    d = beta .- lb .+ sqrt_Î¼
    
    # Barrier contributions
    D_inv = 1.0 ./ d        # For gradient term: Î¼Dâ»Â¹ğŸ™
    D_inv_sq = D_inv .^ 2   # For Hessian term: Î¼Dâ»Â²
    
    # Augmented system: (H + Î¼Dâ»Â²)Î” = g + Î¼Dâ»Â¹ğŸ™
    H_augmented = Symmetric(0.5 * (H_loo + H_loo') + Î¼ * Diagonal(D_inv_sq))
    rhs = g .+ Î¼ .* D_inv
    
    # Solve and return factorization for reuse in gradient computation
    A_fact = try
        cholesky(H_augmented)
    catch
        # Fall back to LU if not positive definite
        lu(H_augmented)
    end
    Î” = A_fact \ rhs
    
    return (Î”=Î”, d=d, D_inv=D_inv, D_inv_sq=D_inv_sq, A_fact=A_fact)
end

# =============================================================================
# Cache Structure for Implicit Differentiation
# =============================================================================

"""
    ImplicitBetaCache{M, D, P}

Cache for implicit differentiation of the inner Î² optimization problem.

Stores all objects needed to:
1. Solve the inner optimization Î²Ì‚(Ï) via forward function
2. Evaluate the optimality conditions c(Ï, Î²) = 0 at any (Ï, Î²)

# Type Parameters
- `M`: Model type (MultistateProcess)
- `D`: Data type (ExactData, MPanelData, or MCEMSelectionData)
- `P`: Penalty configuration type

# Fields
- `model`: Model for likelihood evaluation
- `data`: Data container
- `penalty_config`: Penalty configuration with S matrices
- `S_matrices`: Pre-extracted penalty matrices for fast access
- `lb`, `ub`: Parameter bounds
- `inner_maxiter`: Maximum iterations for inner optimization
- `inner_tol`: Convergence tolerance for inner optimization
"""
struct ImplicitBetaCache{M<:MultistateProcess, D, P<:AbstractPenalty}
    model::M
    data::D
    penalty_config::P
    S_matrices::Vector{Matrix{Float64}}  # Penalty matrices per term
    lb::Vector{Float64}
    ub::Vector{Float64}
    inner_maxiter::Int
    inner_tol::Float64
end

"""
    build_implicit_beta_cache(model, data, penalty, beta_init; kwargs...) -> ImplicitBetaCache

Build cache for implicit differentiation.

# Arguments
- `model::MultistateProcess`: Model for likelihood evaluation
- `data`: Data container (ExactData, MPanelData, or MCEMSelectionData)
- `penalty::AbstractPenalty`: Penalty configuration
- `beta_init::Vector{Float64}`: Initial coefficients (used to determine dimensions)

# Keyword Arguments
- `inner_maxiter::Int=50`: Maximum iterations for inner optimization
- `inner_tol::Float64=1e-6`: Convergence tolerance
"""
function build_implicit_beta_cache(
    model::MultistateProcess,
    data,
    penalty::AbstractPenalty,
    beta_init::Vector{Float64};
    inner_maxiter::Int = 50,
    inner_tol::Float64 = LAMBDA_SELECTION_INNER_TOL
)
    lb, ub = model.bounds.lb, model.bounds.ub
    
    # Extract penalty matrices
    S_matrices = _extract_penalty_matrices(penalty)
    
    return ImplicitBetaCache(
        model, data, penalty, S_matrices,
        lb, ub, inner_maxiter, inner_tol
    )
end

"""
    _extract_penalty_matrices(penalty::QuadraticPenalty) -> Vector{Matrix{Float64}}

Extract penalty matrices from a QuadraticPenalty configuration.
Returns a vector of matrices, one per smoothing parameter.
"""
function _extract_penalty_matrices(penalty::QuadraticPenalty)
    matrices = Matrix{Float64}[]
    
    # Extract from baseline terms
    for term in penalty.terms
        push!(matrices, Matrix(term.S))
    end
    
    # Extract from total hazard terms
    for term in penalty.total_hazard_terms
        push!(matrices, Matrix(term.S))
    end
    
    # Extract from smooth covariate terms
    for term in penalty.smooth_covariate_terms
        push!(matrices, Matrix(term.S))
    end
    
    return matrices
end

# Fallback for other penalty types
function _extract_penalty_matrices(penalty::AbstractPenalty)
    # NoPenalty or unknown type
    return Matrix{Float64}[]
end

# =============================================================================
# Forward Function: Inner Optimization
# =============================================================================

"""
    forward_beta_solve(Ï, cache::ImplicitBetaCache) -> (Î², z)

Forward function for ImplicitDifferentiation.jl.

Solves the penalized MLE problem:
    Î²Ì‚(Ï) = argmin_Î² [-â„“(Î²) + Â½ Î£â±¼ exp(Ïâ±¼) Î²áµ€Sâ±¼Î²]

# Arguments
- `Ï`: Log-smoothing parameters (AbstractVector)
- `cache`: ImplicitBetaCache with model, data, penalty info

# Returns
- `Î²`: Optimal coefficient vector (AbstractVector)
- `z`: Byproduct tuple containing (H_lambda, converged) for diagnostics

# Note
This function extracts Float64 values from Ï (which may contain Dual numbers)
because the inner optimization has its own AD. The outer AD uses the implicit
function theorem to get gradients via the conditions function.
"""
function forward_beta_solve(Ï::AbstractVector, cache::ImplicitBetaCache)
    # Extract Float64 values - inner optimization is Float64 only
    Ï_float = Float64[ForwardDiff.value(x) for x in Ï]
    Î» = exp.(Ï_float)
    
    # Create penalty with current Î»
    penalty = set_hyperparameters(cache.penalty_config, Î»)
    
    # Solve inner problem using existing infrastructure
    # Start from previous Î² if available (warm-starting)
    Î²_init = get_warm_start_beta(cache)
    
    Î²_opt = _fit_inner_coefficients_cached(
        cache.model, cache.data, penalty, Î²_init;
        lb=cache.lb, ub=cache.ub, maxiter=cache.inner_maxiter
    )
    
    # Compute penalized Hessian at solution (for diagnostics/byproduct)
    H_lambda = _compute_penalized_hessian_at_beta(Î²_opt, Î», cache)
    
    # Return Î² and byproduct (including beta_float for KKT-aware conditions)
    return Î²_opt, (beta_float=Î²_opt, H_lambda=H_lambda, lambda=Î»)
end

"""
    get_warm_start_beta(cache::ImplicitBetaCache) -> Vector{Float64}

Get initial Î² for warm-starting the inner optimization.
Currently returns a sensible starting point (handles infinite bounds).
"""
function get_warm_start_beta(cache::ImplicitBetaCache)
    # Smart initialization that handles infinite bounds
    n = length(cache.lb)
    beta_init = Vector{Float64}(undef, n)
    
    for i in 1:n
        li, ui = cache.lb[i], cache.ub[i]
        if isfinite(li) && isfinite(ui)
            # Finite bounds: use midpoint
            beta_init[i] = 0.5 * (li + ui)
        elseif isfinite(li) && !isfinite(ui)
            # Lower bound only: start at lb + 1
            beta_init[i] = li + 1.0
        elseif !isfinite(li) && isfinite(ui)
            # Upper bound only: start at ub - 1
            beta_init[i] = ui - 1.0
        else
            # No finite bounds: use 0
            beta_init[i] = 0.0
        end
    end
    
    return beta_init
end

"""
    _fit_inner_coefficients_cached(model, data, penalty, beta_init; kwargs...) -> Vector{Float64}

Fit coefficients using the appropriate method for the data type.
This dispatches to the existing `_fit_inner_coefficients` functions.
"""
function _fit_inner_coefficients_cached(
    model::MultistateProcess,
    data::ExactData,
    penalty::AbstractPenalty,
    beta_init::Vector{Float64};
    lb::Vector{Float64},
    ub::Vector{Float64},
    maxiter::Int
)
    # Use existing ExactData implementation
    return _fit_inner_coefficients(model, data, penalty, beta_init;
                                    lb=lb, ub=ub, maxiter=maxiter)
end

function _fit_inner_coefficients_cached(
    model::MultistateProcess,
    data::MPanelData,
    penalty::AbstractPenalty,
    beta_init::Vector{Float64};
    lb::Vector{Float64},
    ub::Vector{Float64},
    maxiter::Int
)
    # Use existing MPanelData implementation
    return _fit_inner_coefficients(model, data, penalty, beta_init;
                                    lb=lb, ub=ub, maxiter=maxiter)
end

function _fit_inner_coefficients_cached(
    model::MultistateProcess,
    data::MCEMSelectionData,
    penalty::AbstractPenalty,
    beta_init::Vector{Float64};
    lb::Vector{Float64},
    ub::Vector{Float64},
    maxiter::Int
)
    # Use existing MCEMSelectionData implementation
    return _fit_inner_coefficients(model, data, penalty, beta_init;
                                    lb=lb, ub=ub, maxiter=maxiter)
end

# =============================================================================
# Conditions Function: Optimality (KKT-aware)
# =============================================================================

"""
    beta_optimality_conditions(Ï, Î², z, cache::ImplicitBetaCache) -> Vector

KKT-aware optimality conditions c(Ï, Î²) for the penalized problem.

For interior parameters, the standard first-order condition applies:
    c_i(Ï, Î²) = âˆ‡_Î² â„“(Î²)_i - (Î£â±¼ Î»â±¼ Sâ±¼ Î²)_i = 0

For parameters at active bounds, we use the constraint as the condition:
    c_i(Ï, Î²) = Î²_i - lb_i  (if Î²_i â‰ˆ lb_i)
    c_i(Ï, Î²) = Î²_i - ub_i  (if Î²_i â‰ˆ ub_i)

This ensures âˆ‚c_i/âˆ‚Î²_i = 1 and âˆ‚c_i/âˆ‚Ï = 0 for active bounds, which via the
implicit function theorem gives dÎ²Ì‚_i/dÏ = 0 as expected.

# Arguments
- `Ï`: Log-smoothing parameters (may contain Dual numbers for AD)
- `Î²`: Coefficient vector (may contain Dual numbers for AD)
- `z`: Byproduct from forward solve (contains beta_float for bound detection)
- `cache`: ImplicitBetaCache with model, data, penalty info

# Returns
Vector of condition values (should be â‰ˆ 0 at optimum)

# Note
This function must be AD-compatible as ImplicitDifferentiation.jl will
differentiate through it to compute the Jacobians âˆ‚c/âˆ‚Î² and âˆ‚c/âˆ‚Ï.
"""
function beta_optimality_conditions(Ï::AbstractVector, Î²::AbstractVector, z, cache::ImplicitBetaCache)
    # Convert Ï to Î» (AD-compatible)
    Î» = exp.(Ï)
    n = length(Î²)
    
    # Get Float64 Î² from byproduct for bound detection
    Î²_float = z.beta_float
    lb, ub = cache.lb, cache.ub
    
    # Compute unconstrained gradient conditions
    grad_ll = _compute_ll_gradient(Î², cache)
    grad_penalty = _compute_penalty_gradient(Î², Î», cache)
    unconstrained_conditions = grad_ll - grad_penalty
    
    # Build conditions with KKT-aware handling of active bounds
    T = eltype(unconstrained_conditions)
    conditions = similar(unconstrained_conditions)
    
    for i in 1:n
        if Î²_float[i] - lb[i] < ACTIVE_BOUND_TOL
            # Active at lower bound: condition is Î²_i - lb_i
            # This gives âˆ‚c/âˆ‚Î²_i = 1, âˆ‚c/âˆ‚Ï = 0 â†’ dÎ²Ì‚_i/dÏ = 0
            conditions[i] = Î²[i] - lb[i]
        elseif ub[i] - Î²_float[i] < ACTIVE_BOUND_TOL
            # Active at upper bound: condition is Î²_i - ub_i
            conditions[i] = Î²[i] - ub[i]
        else
            # Interior point: use standard first-order condition
            conditions[i] = unconstrained_conditions[i]
        end
    end
    
    return conditions
end

"""
    _compute_ll_gradient(Î², cache::ImplicitBetaCache{M, ExactData}) -> Vector

Compute gradient of log-likelihood for ExactData.
"""
function _compute_ll_gradient(Î²::AbstractVector, cache::ImplicitBetaCache{M, ExactData}) where M
    # Use ForwardDiff to compute gradient
    grad = ForwardDiff.gradient(b -> loglik_exact(b, cache.data; neg=false), collect(Î²))
    return grad
end

"""
    _compute_ll_gradient(Î², cache::ImplicitBetaCache{M, MPanelData}) -> Vector

Compute gradient of log-likelihood for MPanelData.
"""
function _compute_ll_gradient(Î²::AbstractVector, cache::ImplicitBetaCache{M, MPanelData}) where M
    # Use ForwardDiff to compute gradient
    grad = ForwardDiff.gradient(b -> loglik_markov(b, cache.data; neg=false), collect(Î²))
    return grad
end

"""
    _compute_ll_gradient(Î², cache::ImplicitBetaCache{M, MCEMSelectionData}) -> Vector

Compute gradient of importance-weighted log-likelihood for MCEMSelectionData.
"""
function _compute_ll_gradient(Î²::AbstractVector, cache::ImplicitBetaCache{M, MCEMSelectionData}) where M
    # Create SMPanelData for semi-Markov likelihood
    sm_data = SMPanelData(cache.data.model, cache.data.paths, cache.data.weights)
    # Use ForwardDiff with importance-weighted semi-Markov likelihood
    grad = ForwardDiff.gradient(b -> loglik_semi_markov(b, sm_data; neg=false, use_sampling_weight=true), collect(Î²))
    return grad
end

"""
    _compute_penalty_gradient(Î², Î», cache) -> Vector

Compute gradient of penalty term: Î£â±¼ Î»â±¼ Sâ±¼ Î²

Note: Must be AD-compatible. Both Î² and Î» may contain Dual numbers.
"""
function _compute_penalty_gradient(Î²::AbstractVector, Î»::AbstractVector, cache::ImplicitBetaCache)
    n = length(Î²)
    # Use promoted element type to handle both Î² and Î» potentially having Dual numbers
    T = promote_type(eltype(Î²), eltype(Î»))
    grad = zeros(T, n)
    
    penalty = cache.penalty_config
    lambda_idx = 1
    
    # Baseline hazard penalty gradients
    for term in penalty.terms
        Î²_j = Î²[term.hazard_indices]
        # âˆ‚/âˆ‚Î² (Î»/2 Î²áµ€SÎ²) = Î» S Î²
        grad_j = Î»[lambda_idx] * (term.S * Î²_j)
        grad[term.hazard_indices] .+= grad_j
        lambda_idx += 1
    end
    
    # Total hazard penalty gradients
    for term in penalty.total_hazard_terms
        K = size(term.S, 1)
        Î²_total = zeros(T, K)
        for idx_range in term.hazard_indices
            Î²_total .+= Î²[idx_range]
        end
        # âˆ‚/âˆ‚Î² (Î»/2 Î²_total'SÎ²_total)
        grad_total = Î»[lambda_idx] * (term.S * Î²_total)
        for idx_range in term.hazard_indices
            grad[idx_range] .+= grad_total
        end
        lambda_idx += 1
    end
    
    # Smooth covariate penalty gradients
    if !isempty(penalty.shared_smooth_groups)
        # Build term -> lambda mapping
        term_to_lambda = Dict{Int, Int}()
        for (group_idx, group) in enumerate(penalty.shared_smooth_groups)
            for term_idx in group
                term_to_lambda[term_idx] = lambda_idx
            end
            lambda_idx += 1
        end
        # Handle ungrouped terms
        for term_idx in 1:length(penalty.smooth_covariate_terms)
            if !haskey(term_to_lambda, term_idx)
                term_to_lambda[term_idx] = lambda_idx
                lambda_idx += 1
            end
        end
        # Compute gradients
        for (term_idx, term) in enumerate(penalty.smooth_covariate_terms)
            Î²_k = Î²[term.param_indices]
            grad_k = Î»[term_to_lambda[term_idx]] * (term.S * Î²_k)
            grad[term.param_indices] .+= grad_k
        end
    else
        for term in penalty.smooth_covariate_terms
            Î²_k = Î²[term.param_indices]
            grad_k = Î»[lambda_idx] * (term.S * Î²_k)
            grad[term.param_indices] .+= grad_k
            lambda_idx += 1
        end
    end
    
    return grad
end

"""
    _compute_penalized_hessian_at_beta(Î², Î», cache) -> Matrix{Float64}

Compute the penalized Hessian H_Î» = -âˆ‡Â²â„“(Î²) + Î£â±¼ Î»â±¼ Sâ±¼ at given Î².
"""
function _compute_penalized_hessian_at_beta(Î²::Vector{Float64}, Î»::Vector{Float64}, 
                                            cache::ImplicitBetaCache{M, ExactData}) where M
    # Get unpenalized Hessian
    H_unpenalized = ForwardDiff.hessian(b -> loglik_exact(b, cache.data; neg=true), Î²)
    
    # Add penalty contributions
    n = length(Î²)
    H_lambda = copy(H_unpenalized)
    
    penalty = cache.penalty_config
    lambda_idx = 1
    
    for term in penalty.terms
        idx = term.hazard_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    for term in penalty.total_hazard_terms
        # For total hazard terms, the Hessian contribution is spread across indices
        for idx_range1 in term.hazard_indices
            for idx_range2 in term.hazard_indices
                H_lambda[idx_range1, idx_range2] .+= Î»[lambda_idx] * term.S
            end
        end
        lambda_idx += 1
    end
    
    for term in penalty.smooth_covariate_terms
        idx = term.param_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    return H_lambda
end

# =============================================================================
# Implicit Function Factory
# =============================================================================

"""
    make_implicit_beta_function(cache::ImplicitBetaCache) -> ImplicitFunction

Create an ImplicitFunction for Î²Ì‚(Ï) that can be differentiated w.r.t. Ï.

The returned function has signature:
    Î², z = implicit_beta(Ï)

where:
- `Ï`: Log-smoothing parameters
- `Î²`: Optimal coefficients (differentiable w.r.t. Ï)
- `z`: Byproduct (H_lambda, converged)

# Example
```julia
cache = build_implicit_beta_cache(model, data, penalty, beta_init)
implicit_beta = make_implicit_beta_function(cache)

# Use in optimization
function criterion(Ï)
    Î², _ = implicit_beta(Ï)
    return compute_V(Î², Ï, ...)
end

# ForwardDiff works through the implicit function
grad = ForwardDiff.gradient(criterion, Ï_init)
```
"""
function make_implicit_beta_function(cache::ImplicitBetaCache)
    # Forward function
    forward = Ï -> forward_beta_solve(Ï, cache)
    
    # Conditions function (needs all 4 args: x, y, z, extras...)
    conditions = (Ï, Î², z) -> beta_optimality_conditions(Ï, Î², z, cache)
    
    # Create ImplicitFunction with direct linear solver
    # Use MatrixRepresentation (required for DirectLinearSolver) and
    # ADTypes.AutoForwardDiff for both x and y derivatives
    return ImplicitFunction(
        forward,
        conditions;
        representation=MatrixRepresentation(),  # Must use MatrixRepresentation with DirectLinearSolver
        linear_solver=DirectLinearSolver(),
        backends=(x=AutoForwardDiff(), y=AutoForwardDiff())
    )
end

# =============================================================================
# PIJCV Criterion with Implicit Differentiation
# =============================================================================

"""
    compute_ncv_at_beta(Î², Ï, cache::ImplicitBetaCache; nfolds=0) -> Float64

Compute the NCV/PIJCV criterion at given (Î², Ï).

This is the second stage of PIJCV with implicit differentiation:
1. Get Î²Ì‚(Ï) via implicit function (handles âˆ‚Î²Ì‚/âˆ‚Ï)
2. Compute V(Ï) = Î£áµ¢ Dáµ¢(Î²Ì‚â»â±) using Newton approximation

The gradients/Hessians for V are computed at Float64, not Dual, because
all the necessary derivatives w.r.t. Ï come through Î²Ì‚ via implicit diff.

# Arguments
- `Î²`: Current coefficient estimate
- `Ï`: Log-smoothing parameters
- `cache`: ImplicitBetaCache
- `nfolds`: 0 for LOO, k for k-fold approximation

# Returns
Scalar criterion value (lower is better)
"""
function compute_ncv_at_beta(Î²::AbstractVector, Ï::AbstractVector, cache::ImplicitBetaCache; 
                              nfolds::Int=0, use_quadratic::Bool=false)
    # Extract Float64 for gradient/Hessian computation
    Î²_float = Float64[ForwardDiff.value(x) for x in Î²]
    Ï_float = Float64[ForwardDiff.value(x) for x in Ï]
    Î» = exp.(Ï_float)
    
    # Compute subject gradients and Hessians (Float64)
    # This is the expensive part but does NOT need to be differentiated w.r.t. Ï
    # because that information comes through Î² via implicit differentiation
    subject_grads, subject_hessians = _compute_subject_grads_hessians(Î²_float, cache)
    
    # Build state for criterion evaluation
    H_unpenalized = sum(subject_hessians)
    n_subjects = length(subject_grads[1, :])
    n_params = length(Î²_float)
    
    penalty_config = cache.penalty_config
    
    state = SmoothingSelectionState(
        Î²_float,
        H_unpenalized,
        hcat(subject_grads...),  # p Ã— n matrix
        subject_hessians,
        penalty_config,
        n_subjects,
        n_params,
        cache.model,
        cache.data,
        nothing  # pijcv_eval_cache - will be built lazily
    )
    
    # Compute criterion using existing function
    log_lambda = collect(Ï_float)  # Convert to plain Vector for criterion
    
    if use_quadratic
        return compute_pijcv_criterion_fast(log_lambda, state)
    elseif nfolds == 0
        return compute_pijcv_criterion(log_lambda, state)
    else
        return compute_pijkfold_criterion(log_lambda, state, nfolds)
    end
end

"""
    _compute_subject_grads_hessians(Î², cache::ImplicitBetaCache{M, ExactData}) -> (grads, hessians)

Compute per-subject gradients and Hessians for ExactData.

# Type Handling
This function accepts AbstractVector{T} to allow Dual numbers from ForwardDiff,
but extracts Float64 values internally. The gradient information w.r.t. Ï flows
through the ImplicitFunction's IFT, not through this computation.
"""
function _compute_subject_grads_hessians(Î²::AbstractVector{T}, cache::ImplicitBetaCache{M, ExactData}) where {T<:Real, M}
    # Extract Float64 values - subject grads/Hessians are treated as constants
    # The Dual information flows through ImplicitFunction's IFT
    Î²_float = T === Float64 ? Î² : Float64[ForwardDiff.value(x) for x in Î²]
    
    samplepaths = cache.data.paths
    
    # Use existing parallel implementation
    grads_ll, hessians_ll = compute_subject_grads_and_hessians_fast(
        Î²_float, cache.model, samplepaths; use_threads=:auto
    )
    
    # Convert to loss convention (negative log-likelihood)
    grads = -grads_ll
    hessians = [-H for H in hessians_ll]
    
    return grads, hessians
end

# =============================================================================
# AD-Compatible PIJCV Criterion for Implicit Differentiation
# =============================================================================

"""
    compute_pijcv_criterion_implicit(Î², log_lambda, cache::ImplicitBetaCache;
                                     pijcv_eval_cache=nothing) -> V

Compute PIJCV criterion V(Ï) that is AD-compatible for implicit differentiation.

This function computes subject gradients/Hessians fresh at each call using the
current Î²Ì‚(Ï) value. This ensures that when ForwardDiff evaluates V at different
Ï values (for numerical differentiation), each evaluation uses the correct 
gáµ¢(Î²Ì‚(Ï)) and Háµ¢(Î²Ì‚(Ï)), capturing the full dependence of V on Ï.

# Mathematical Background

The PIJCV criterion (Wood 2024) is:
    V(Ï) = Î£áµ¢ Dáµ¢(Î²Ì‚â»â±) = Î£áµ¢ [-â„“áµ¢(Î²Ì‚) + gáµ¢áµ€Î”â»â± + Â½Î”â»â±áµ€Háµ¢Î”â»â±]

where:
- Î²Ì‚ = Î²Ì‚(Ï) is the penalized MLE at smoothing parameter Î» = exp(Ï)
- gáµ¢ = -âˆ‡â„“áµ¢(Î²Ì‚) is the negative gradient of subject i's log-likelihood
- Háµ¢ = -âˆ‡Â²â„“áµ¢(Î²Ì‚) is the negative Hessian of subject i's log-likelihood
- Î”â»â± = (H_Î» - Háµ¢)â»Â¹ gáµ¢ is the LOO Newton step

The gradient âˆ‚V/âˆ‚Ï captures dependence through:
1. Î» = exp(Ï) directly in H_Î» (captured by AD on log_lambda)
2. Î²Ì‚(Ï) in gáµ¢, Háµ¢, and -â„“áµ¢ (captured by fresh recomputation)

# Arguments
- `Î²::AbstractVector`: Current coefficients (may be dual numbers from ImplicitFunction)
- `log_lambda::AbstractVector`: Log-smoothing parameters (may be dual numbers)
- `cache::ImplicitBetaCache{M, ExactData}`: Contains model, data, penalty info
- `pijcv_eval_cache`: (unused, for API compatibility)

# Returns
- Scalar criterion value (same numeric type as Î» for AD compatibility)
"""
function compute_pijcv_criterion_implicit(
    Î²::AbstractVector{T1},
    log_lambda::AbstractVector{T2},
    cache::ImplicitBetaCache{M, ExactData};
    pijcv_eval_cache = nothing
) where {T1<:Real, T2<:Real, M}
    # Promote to common type for proper AD
    T = promote_type(T1, T2)
    
    lambda = exp.(log_lambda)
    n_params = length(Î²)
    
    # ==========================================================================
    # CRITICAL: Recompute subject grads/hessians at current Î²Ì‚(Ï)
    # ==========================================================================
    # The PIJCV criterion depends on Ï through TWO paths:
    #   1. Î» = exp(Ï) directly in H_Î»
    #   2. Î²Ì‚(Ï) in gáµ¢(Î²Ì‚), Háµ¢(Î²Ì‚), and -â„“áµ¢(Î²Ì‚)
    # 
    # By recomputing gáµ¢ and Háµ¢ at the current Î²Ì‚, we ensure that when 
    # ForwardDiff evaluates V at different Ï values, each evaluation uses
    # the correct gradients/Hessians for that Ï. This captures the full
    # dependence âˆ‚V/âˆ‚Ï = âˆ‚V/âˆ‚Î² Â· âˆ‚Î²Ì‚/âˆ‚Ï + âˆ‚V/âˆ‚Î» Â· âˆ‚Î»/âˆ‚Ï through function
    # evaluation rather than through explicit AD.
    # ==========================================================================
    Î²_float = Float64[ForwardDiff.value(x) for x in Î²]
    subject_grads, subject_hessians = _compute_subject_grads_hessians(Î²_float, cache)
    H_unpenalized = sum(subject_hessians)
    n_subjects = size(subject_grads, 2)
    
    # Build penalized Hessian with dual-number Î»
    # H_Î» = H_unpen + Î£â±¼ Î»â±¼ Sâ±¼
    # Must iterate through penalty terms and add contributions at correct indices
    H_lambda = Matrix{T}(H_unpenalized)  # Convert to appropriate type
    
    penalty = cache.penalty_config
    lambda_idx = 1
    
    # Baseline hazard penalty contributions
    for term in penalty.terms
        idx = term.hazard_indices
        Î»_j = lambda_idx <= length(lambda) ? lambda[lambda_idx] : lambda[1]
        H_lambda[idx, idx] .+= Î»_j .* term.S
        lambda_idx += 1
    end
    
    # Total hazard penalty contributions
    for term in penalty.total_hazard_terms
        Î»_j = lambda_idx <= length(lambda) ? lambda[lambda_idx] : lambda[1]
        for idx_range1 in term.hazard_indices
            for idx_range2 in term.hazard_indices
                H_lambda[idx_range1, idx_range2] .+= Î»_j .* term.S
            end
        end
        lambda_idx += 1
    end
    
    # Smooth covariate penalty contributions
    for term in penalty.smooth_covariate_terms
        idx = term.param_indices
        Î»_j = lambda_idx <= length(lambda) ? lambda[lambda_idx] : lambda[1]
        H_lambda[idx, idx] .+= Î»_j .* term.S
        lambda_idx += 1
    end
    
    # ==========================================================================
    # PIJCV COMPUTATION
    # ==========================================================================
    # The PIJCV criterion: V(Ï) = Î£áµ¢ Dáµ¢ where Dáµ¢ = -â„“áµ¢(Î²Ì‚) + gáµ¢áµ€Î”â»â± + Â½Î”â»â±áµ€Háµ¢Î”â»â±
    # with Î”â»â± = H_{Î»,-i}â»Â¹ gáµ¢ being the LOO Newton step.
    #
    # The gradient âˆ‚V/âˆ‚Ï is computed via finite differences through function
    # evaluation: when Ï changes, Î²Ì‚(Ï) changes, which changes gáµ¢, Háµ¢, and â„“áµ¢.
    # By recomputing subject_grads/hessians at each call (done above), we
    # ensure correct function evaluation at each Ï value.
    #
    # Note: Î» = exp(Ï) affects V directly through H_lambda. This is captured
    # by AD on log_lambda in the H_lambda construction above.
    # ==========================================================================
    
    # Get subject log-likelihoods at current Î²
    ll_subj_base = loglik_exact(Î²_float, cache.data; neg=false, return_ll_subj=true)
    
    # Compute V_q using quadratic approximation
    V = T(0)
    
    for i in 1:n_subjects
        g_i = @view subject_grads[:, i]
        H_i = subject_hessians[i]
        
        # Leave-one-out penalized Hessian: H_{Î»,-i} = H_Î» - H_i
        # Note: H_i is Float64, H_lambda is type T
        H_lambda_loo = H_lambda - Matrix{T}(H_i)
        
        # Solve for Newton step: Î”â»â± = H_{Î»,-i}â»Â¹ gáµ¢
        delta_i = try
            Symmetric(H_lambda_loo) \ collect(g_i)
        catch e
            # If solve fails, return large penalty
            @debug "Linear solve failed in compute_pijcv_criterion_implicit" subject=i
            return T(1e10)
        end
        
        # Quadratic approximation components
        linear_term = dot(g_i, delta_i)
        quadratic_term = T(0.5) * dot(delta_i, H_i * delta_i)
        
        # Subject contribution
        D_i = T(-ll_subj_base[i]) + linear_term + quadratic_term
        
        V += D_i
    end
    
    return V
end

# Similar implementations for MPanelData and MCEMSelectionData would be added here...

# =============================================================================
# AD-Compatible V(Î², Ï) for ForwardDiff Through ImplicitFunction
# =============================================================================

"""
    compute_V_at_beta(Î², Ï, cache::ImplicitBetaCache) -> V

Compute PIJCV criterion V(Ï) at given (Î², Ï) in an AD-compatible way.

This is the key function for nested AD through ImplicitFunction:
```julia
function pijcv_objective(Ï)
    implicit_beta = make_implicit_beta_function(cache)
    Î²Ì‚, z = implicit_beta(Ï)
    return compute_V_at_beta(Î²Ì‚, Ï, cache)
end
grad = ForwardDiff.gradient(pijcv_objective, Ï_init)
```

The full chain rule âˆ‚V/âˆ‚Ï = âˆ‚V/âˆ‚Î² Â· âˆ‚Î²Ì‚/âˆ‚Ï + âˆ‚V/âˆ‚Î» Â· âˆ‚Î»/âˆ‚Ï is handled by:
- compute_pijcv_criterion_implicit recomputes gáµ¢(Î²Ì‚), Háµ¢(Î²Ì‚) at each call
- This captures Î² dependence through function evaluation
- Î» dependence is captured by AD on log_lambda in H_lambda construction

# Arguments
- `Î²::AbstractVector`: Coefficient vector (may contain Dual numbers from ImplicitFunction)
- `Ï::AbstractVector`: Log-smoothing parameters (may contain Dual numbers)
- `cache::ImplicitBetaCache`: Contains model, data, penalty info

# Returns
Scalar criterion value V (same numeric type as Î» for AD compatibility)
"""
function compute_V_at_beta(Î²::AbstractVector, Ï::AbstractVector, 
                           cache::ImplicitBetaCache{M, ExactData}) where {M}
    # Delegate to the criterion function which handles everything
    return compute_pijcv_criterion_implicit(Î², Ï, cache)
end

"""
    make_pijcv_objective(cache::ImplicitBetaCache) -> Function

Create a PIJCV objective function Ï â†’ V(Ï) that can be differentiated with ForwardDiff.

Returns a closure that:
1. Computes Î²Ì‚(Ï) via the ImplicitFunction
2. Evaluates V(Î²Ì‚, Ï) with proper AD chain rule handling

# Example
```julia
cache = build_implicit_beta_cache(model, data, penalty, beta_init)
pijcv_obj = make_pijcv_objective(cache)

# Evaluate
V = pijcv_obj(log_lambda)

# Gradient via ForwardDiff
grad_V = ForwardDiff.gradient(pijcv_obj, log_lambda)
```
"""
function make_pijcv_objective(cache::ImplicitBetaCache)
    implicit_beta = make_implicit_beta_function(cache)
    
    return function pijcv_objective(Ï::AbstractVector)
        Î²Ì‚, _ = implicit_beta(Ï)
        return compute_V_at_beta(Î²Ì‚, Ï, cache)
    end
end


# =============================================================================
# SIGN CONVENTIONS (see scratch/PIJCV_IMPLICIT_DIFF_HANDOFF_2026-01-27.md)
# =============================================================================
# subject_grads[:, i] = gáµ¢ = -âˆ‡â„“áµ¢(Î²Ì‚)     (loss gradient, NEGATIVE of loglik gradient)
# subject_hessians[i] = Háµ¢ = -âˆ‡Â²â„“áµ¢(Î²Ì‚)    (loss Hessian, NEGATIVE of loglik Hessian)
# H_Î» = Î£â±¼ Hâ±¼ + Î»S                        (penalized Hessian)
# H_{-i} = H_Î» - Háµ¢                       (leave-one-out Hessian)
# Î´áµ¢ = H_{-i}â»Â¹ gáµ¢                        (Newton step)
# Î²Ìƒ_{-i} = Î²Ì‚ + Î´áµ¢                        (pseudo-estimate, PLUS sign)
# V = Î£áµ¢ -â„“áµ¢(Î²Ìƒ_{-i})                      (criterion to minimize)
# =============================================================================

# =============================================================================
# Analytical Gradient for PIJCV Criterion
# =============================================================================

"""
    compute_pijcv_with_gradient(Î², log_lambda, cache::ImplicitBetaCache;
                                 subject_grads, subject_hessians, H_unpenalized,
                                 dbeta_drho, subject_third_derivatives=nothing) -> (V, grad_V)

Compute PIJCV criterion V(Ï) AND its **CORRECT** analytical gradient âˆ‡V simultaneously.

# Mathematical Background (Wood 2024, corrected for third derivatives)

The CORRECT PIJCV criterion (NCV, Wood 2024, Equation 2) is:

    V(Ï) = Î£áµ¢ -â„“áµ¢(Î²Ìƒâ‚‹áµ¢)

where:
- Î²Ìƒâ‚‹áµ¢ = Î²Ì‚ + Î”â»â± is the pseudo-estimate (one Newton step from Î²Ì‚ toward LOO optimum)
- Î”â»â± = (H_Î» - Háµ¢)â»Â¹ gáµ¢ is the LOO step
- gáµ¢ = -âˆ‡â„“áµ¢(Î²Ì‚) is the per-subject LOSS gradient (negative of loglik gradient)
- Háµ¢ = -âˆ‡Â²â„“áµ¢(Î²Ì‚) is the per-subject LOSS Hessian (negative of loglik Hessian)

## CORRECT Gradient Formula (with third derivatives)

    dV/dÏ = Î£áµ¢ [-âˆ‡â„“áµ¢(Î²Ìƒâ‚‹áµ¢)áµ€ Â· dÎ²Ìƒâ‚‹áµ¢/dÏ]

where dÎ²Ìƒâ‚‹áµ¢/dÏ = dÎ²Ì‚/dÏ + dÎ”â»â±/dÏ (PLUS sign!) and the chain rule gives:

    dÎ”â»â±/dÏ = H_looâ»Â¹ Â· [dgáµ¢/dÏ - dH_loo/dÏ Â· Î”â»â±]

with:
- dgáµ¢/dÏ = +Háµ¢ Â· dÎ²Ì‚/dÏ (POSITIVE sign: gáµ¢ = -âˆ‡â„“áµ¢, so dgáµ¢/dÏ = -âˆ‡Â²â„“áµ¢ Â· dÎ²Ì‚/dÏ = Háµ¢ Â· dÎ²Ì‚/dÏ)
- dH_loo/dÏ = dH_Î»/dÏ - dHáµ¢/dÏ
- dH_Î»/dÏ = Î»S + Î£â±¼ Î£â‚— (âˆ‚Hâ±¼/âˆ‚Î²â‚—) Â· (dÎ²Ì‚/dÏ)â‚—  [includes third derivatives!]
- dHáµ¢/dÏ = Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—) Â· (dÎ²Ì‚/dÏ)â‚—

## Critical Implementation Note

The previous implementation neglected the third derivative terms (âˆ‚Háµ¢/âˆ‚Î²), causing
~30% bias in optimal Î» selection. This corrected version includes the full chain rule.

# Arguments
- `Î²::Vector{Float64}`: Current coefficient estimate (Î²Ì‚)
- `log_lambda::Vector{Float64}`: Log-smoothing parameters (Ï)
- `cache::ImplicitBetaCache`: Contains model, data, penalty info
- `subject_grads::Matrix{Float64}`: Per-subject loss gradients (p Ã— n), gáµ¢ = -âˆ‡â„“áµ¢(Î²Ì‚)
- `subject_hessians::Vector{Matrix{Float64}}`: Per-subject loss Hessians, Háµ¢ = -âˆ‡Â²â„“áµ¢(Î²Ì‚)
- `H_unpenalized::Matrix{Float64}`: Sum of subject Hessians
- `dbeta_drho::Vector{Float64}`: dÎ²Ì‚/dÏ from ImplicitDifferentiation.jl
- `subject_third_derivatives::Union{Nothing, Vector}=nothing`: Pre-computed âˆ‚Háµ¢/âˆ‚Î² tensors

# Returns
- `V::Float64`: Criterion value (lower is better)
- `grad_V::Vector{Float64}`: Gradient w.r.t. log(Î»)

# References
- Wood, S.N. (2024). "On Neighbourhood Cross Validation." arXiv:2404.16490v4
"""
function compute_pijcv_with_gradient(
    Î²::Vector{Float64},
    log_lambda::Vector{Float64},
    cache::ImplicitBetaCache;
    subject_grads::Matrix{Float64},
    subject_hessians::Vector{<:Matrix{Float64}},
    H_unpenalized::Matrix{Float64},
    dbeta_drho::AbstractMatrix{Float64},  # (n_params Ã— n_lambda) matrix
    subject_third_derivatives::Union{Nothing, Vector{Array{Float64,3}}} = nothing,
    check_conditioning::Bool = false  # Disabled by default for performance during optimization
)
    lambda = exp.(log_lambda)
    n_lambda = length(lambda)
    n_subjects = size(subject_grads, 2)
    n_params = length(Î²)
    
    # ==========================================================================
    # Build penalized Hessian H_Î» and per-Î» penalty matrices S_by_lambda
    # Uses same termâ†’Î»â±¼ mapping as _compute_penalty_gradient
    # ==========================================================================
    H_lambda = copy(H_unpenalized)
    S_by_lambda = [zeros(n_params, n_params) for _ in 1:n_lambda]
    penalty = cache.penalty_config
    lambda_idx = 1
    
    # Baseline hazard terms: each term gets its own Î»
    for term in penalty.terms
        idx = term.hazard_indices
        Î»_j = lambda_idx <= n_lambda ? lambda[lambda_idx] : lambda[end]
        H_lambda[idx, idx] .+= Î»_j .* term.S
        if lambda_idx <= n_lambda
            S_by_lambda[lambda_idx][idx, idx] .= Matrix(term.S)
        end
        lambda_idx += 1
    end
    
    # Total hazard terms
    for term in penalty.total_hazard_terms
        Î»_j = lambda_idx <= n_lambda ? lambda[lambda_idx] : lambda[end]
        for idx_range1 in term.hazard_indices
            for idx_range2 in term.hazard_indices
                H_lambda[idx_range1, idx_range2] .+= Î»_j .* term.S
                if lambda_idx <= n_lambda
                    S_by_lambda[lambda_idx][idx_range1, idx_range2] .= Matrix(term.S)
                end
            end
        end
        lambda_idx += 1
    end
    
    # Smooth covariate terms (handle shared_smooth_groups)
    if !isempty(penalty.shared_smooth_groups)
        # Build term -> lambda mapping for shared groups
        term_to_lambda = Dict{Int, Int}()
        for (group_idx, group) in enumerate(penalty.shared_smooth_groups)
            for term_idx in group
                term_to_lambda[term_idx] = lambda_idx
            end
            lambda_idx += 1
        end
        # Handle ungrouped terms
        for term_idx in 1:length(penalty.smooth_covariate_terms)
            if !haskey(term_to_lambda, term_idx)
                term_to_lambda[term_idx] = lambda_idx
                lambda_idx += 1
            end
        end
        # Apply penalties
        for (term_idx, term) in enumerate(penalty.smooth_covariate_terms)
            idx = term.param_indices
            Î»_idx_j = term_to_lambda[term_idx]
            Î»_j = Î»_idx_j <= n_lambda ? lambda[Î»_idx_j] : lambda[end]
            H_lambda[idx, idx] .+= Î»_j .* term.S
            if Î»_idx_j <= n_lambda
                S_by_lambda[Î»_idx_j][idx, idx] .+= Matrix(term.S)  # += for shared groups
            end
        end
    else
        for term in penalty.smooth_covariate_terms
            idx = term.param_indices
            Î»_j = lambda_idx <= n_lambda ? lambda[lambda_idx] : lambda[end]
            H_lambda[idx, idx] .+= Î»_j .* term.S
            if lambda_idx <= n_lambda
                S_by_lambda[lambda_idx][idx, idx] .= Matrix(term.S)
            end
            lambda_idx += 1
        end
    end
    
    H_lambda_sym = Symmetric(H_lambda)
    
    # ==========================================================================
    # Compute third derivative contractions using JVP (Phase 4.3 optimization)
    # Instead of materializing pÃ—pÃ—p tensors, we compute Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·vâ‚— directly
    # for each direction v = dbeta_drho[:, j].
    # ==========================================================================
    # dH_times_v[i][j] = Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·(dÎ²Ì‚/dÏâ±¼)â‚—  (pÃ—p matrix)
    dH_times_v_all = _compute_all_dH_times_v(Î², dbeta_drho, cache)
    
    # ==========================================================================
    # Compute dH_Î»/dÏâ±¼ for each smoothing parameter j
    # dH_Î»/dÏâ±¼ = Î»â±¼ Sâ±¼ + Î£áµ¢ [Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·(dÎ²Ì‚/dÏâ±¼)â‚—]
    # ==========================================================================
    dH_lambda_drho = [lambda[j] * S_by_lambda[j] for j in 1:n_lambda]
    for i in 1:n_subjects
        for j in 1:n_lambda
            dH_lambda_drho[j] .+= dH_times_v_all[i][j]
        end
    end
    
    # ==========================================================================
    # Build PIJCV evaluation cache for efficient LOO likelihood evaluation
    # ==========================================================================
    eval_cache = build_pijcv_eval_cache(cache.data)
    
    # ==========================================================================
    # CORRECT PIJCV: V = Î£áµ¢ -â„“áµ¢(Î²Ìƒâ‚‹áµ¢) where Î²Ìƒâ‚‹áµ¢ = Î²Ì‚ + Î”â»â± (PLUS sign!)
    # Uses barrier-augmented Newton step to ensure Î²Ìƒâ‚‹áµ¢ â‰¥ lb (Phase 7)
    # ==========================================================================
    V = 0.0
    grad_V = zeros(n_lambda)
    
    # Preallocate work vectors (Phase 4 optimization)
    diff_result = DiffResults.GradientResult(zeros(n_params))
    
    # Conditioning diagnostics
    ill_conditioned_subjects = Int[]
    worst_cond = 0.0
    worst_subject = 0
    
    # Barrier parameter (must match solve_hloo_barrier)
    Î¼ = 1e-6
    lb = cache.lb
    
    for i in 1:n_subjects
        gáµ¢ = subject_grads[:, i]
        Háµ¢ = subject_hessians[i]
        dHáµ¢_times_v = dH_times_v_all[i]  # Pre-computed JVP contractions for subject i
        
        # Leave-one-out penalized Hessian
        H_loo = H_lambda - Háµ¢
        
        # Check LOO conditioning if requested
        if check_conditioning
            cond_num, is_ill_cond = check_loo_conditioning(H_loo, i)
            if is_ill_cond
                push!(ill_conditioned_subjects, i)
            end
            if cond_num > worst_cond
                worst_cond = cond_num
                worst_subject = i
            end
        end
        
        # Barrier-augmented Newton step: ensures Î²Ìƒâ‚‹áµ¢ â‰¥ lb (Phase 7)
        # Î”áµ¢ = (H_loo + Î¼Dâ»Â²)â»Â¹ (gáµ¢ + Î¼Dâ»Â¹ğŸ™) where D = Î² - lb + âˆšÎ¼
        barrier_result = solve_hloo_barrier(H_loo, gáµ¢, lb, Î²; Î¼=Î¼)
        Î”áµ¢ = barrier_result.Î”
        d_i = barrier_result.d
        D_inv_i = barrier_result.D_inv
        D_inv_sq_i = barrier_result.D_inv_sq
        A_fact_i = barrier_result.A_fact
        
        if any(isnan, Î”áµ¢)
            return (1e10, fill(0.0, n_lambda))
        end
        
        # Pseudo-estimate: Î²Ìƒâ‚‹áµ¢ = Î²Ì‚ + Î”â»â± (PLUS sign!)
        Î²_tilde_i = Î² .+ Î”áµ¢
        
        # CORRECT criterion: evaluate ACTUAL likelihood at pseudo-estimate
        # Use DiffResults to compute value and gradient in single pass (Phase 4)
        ForwardDiff.gradient!(
            diff_result,
            b -> loglik_subject_cached(b, eval_cache, i),
            Î²_tilde_i
        )
        ll_at_pseudo = DiffResults.value(diff_result)
        grad_ll_at_pseudo = DiffResults.gradient(diff_result)
        
        V_i = -ll_at_pseudo
        V += V_i
        
        # =======================================================================
        # CORRECT gradient with third derivatives AND barrier terms for each Î»â±¼
        # (Phase 7: barrier-augmented gradient)
        # =======================================================================
        # dVáµ¢/dÏâ±¼ = -âˆ‡â„“áµ¢(Î²Ìƒâ‚‹áµ¢)áµ€ Â· dÎ²Ìƒâ‚‹áµ¢/dÏâ±¼
        # where dÎ²Ìƒâ‚‹áµ¢/dÏâ±¼ = dÎ²Ì‚/dÏâ±¼ + dÎ”â»â±/dÏâ±¼ (PLUS sign!)
        #
        # For barrier-augmented step Î” = Aâ»Â¹b where A = H_loo + Î¼Dâ»Â², b = g + Î¼Dâ»Â¹ğŸ™:
        #   dÎ”/dÏâ±¼ = Aâ»Â¹(db/dÏâ±¼ - dA/dÏâ±¼Â·Î”)
        
        for j in 1:n_lambda
            dbeta_j = view(dbeta_drho, :, j)
            
            # --- Barrier derivative terms (Phase 7) ---
            # D = Î² - L + âˆšÎ¼, so dD/dÏâ±¼ = dÎ²Ì‚/dÏâ±¼ (element-wise)
            dD_drho_j = dbeta_j
            
            # d(Dâ»Â¹)/dÏâ±¼ = -Dâ»Â² Â· dD/dÏâ±¼ (element-wise)
            d_D_inv_drho_j = -(D_inv_i .^ 2) .* dD_drho_j
            
            # d(Dâ»Â²)/dÏâ±¼ = -2Dâ»Â³ Â· dD/dÏâ±¼ (element-wise)
            d_D_inv_sq_drho_j = -2.0 .* (D_inv_i .^ 3) .* dD_drho_j
            
            # --- db/dÏâ±¼ = dgáµ¢/dÏâ±¼ + Î¼Â·d(Dâ»Â¹ğŸ™)/dÏâ±¼ ---
            # dgáµ¢/dÏâ±¼ = +Háµ¢Â·dÎ²Ì‚/dÏâ±¼ (POSITIVE sign!)
            dgáµ¢_drho_j = Háµ¢ * dbeta_j
            db_drho_j = dgáµ¢_drho_j .+ Î¼ .* d_D_inv_drho_j
            
            # --- dA/dÏâ±¼ = dH_{-i}/dÏâ±¼ + Î¼Â·diag(d(Dâ»Â²)/dÏâ±¼) ---
            # dHáµ¢/dÏâ±¼ = Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·(dÎ²Ì‚/dÏâ±¼)â‚— (pre-computed via JVP, Phase 4.3)
            dHáµ¢_drho_j = dHáµ¢_times_v[j]
            
            # dH_loo/dÏâ±¼ = dH_Î»/dÏâ±¼ - dHáµ¢/dÏâ±¼
            dH_loo_drho_j = dH_lambda_drho[j] - dHáµ¢_drho_j
            
            # Add barrier Hessian derivative (diagonal term): Î¼Â·diag(d(Dâ»Â²)/dÏâ±¼)
            dA_drho_j = dH_loo_drho_j + Î¼ * Diagonal(d_D_inv_sq_drho_j)
            
            # --- dÎ”/dÏâ±¼ = Aâ»Â¹(db/dÏâ±¼ - dA/dÏâ±¼Â·Î”) ---
            # Reuse A_fact_i from solve_hloo_barrier
            rhs_for_dDelta = db_drho_j - dA_drho_j * Î”áµ¢
            dDelta_drho_j = A_fact_i \ rhs_for_dDelta
            
            if any(isnan, dDelta_drho_j)
                continue
            end
            
            # dÎ²Ìƒâ‚‹áµ¢/dÏâ±¼ = dÎ²Ì‚/dÏâ±¼ + dÎ”â»â±/dÏâ±¼ (PLUS sign!)
            dbeta_tilde_drho_j = dbeta_j + dDelta_drho_j
            
            # dVáµ¢/dÏâ±¼ = -âˆ‡â„“áµ¢(Î²Ìƒâ‚‹áµ¢)áµ€ Â· dÎ²Ìƒâ‚‹áµ¢/dÏâ±¼
            dV_i_drho_j = -dot(grad_ll_at_pseudo, dbeta_tilde_drho_j)
            grad_V[j] += dV_i_drho_j
        end
    end
    
    # Log conditioning summary if issues were detected
    if check_conditioning && !isempty(ill_conditioned_subjects)
        report = LOOConditioningReport(
            length(ill_conditioned_subjects),
            ill_conditioned_subjects,
            worst_cond,
            worst_subject
        )
        log_loo_conditioning_summary(report, n_subjects; context="PIJCV gradient")
    end
    
    return (V, grad_V)
end


"""
    _compute_subject_third_derivatives(Î², cache::ImplicitBetaCache) -> Vector{Array{Float64,3}}

Compute third derivatives âˆ‚Háµ¢/âˆ‚Î² for all subjects.

Returns a vector of 3D tensors, one per subject. Each tensor has shape
(n_params, n_params, n_params) where tensor[:,:,l] is the derivative of
the subject's Hessian with respect to Î²â‚—.

# Implementation
Uses ForwardDiff.jacobian on the flattened Hessian:
    âˆ‚Háµ¢/âˆ‚Î² = reshape(ForwardDiff.jacobian(Î² â†’ vec(Háµ¢(Î²)), Î²), n_params, n_params, n_params)

# Note
This function materializes full pÃ—pÃ—p tensors and is O(pÂ³) in memory.
For large p, prefer using `_compute_dH_times_v` which computes the 
contraction Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·vâ‚— directly using directional derivatives.
"""
function _compute_subject_third_derivatives(Î²::Vector{Float64}, cache::ImplicitBetaCache{M, ExactData}) where M
    n_subjects = length(cache.data.paths)
    n_params = length(Î²)
    
    third_derivs = Vector{Array{Float64,3}}(undef, n_subjects)
    
    for i in 1:n_subjects
        # Compute Jacobian of flattened Hessian
        H_flat_jac = ForwardDiff.jacobian(
            b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, i), b)),
            Î²
        )
        # Reshape to tensor: third_derivs[i][:,:,l] = âˆ‚Háµ¢/âˆ‚Î²â‚—
        third_derivs[i] = reshape(H_flat_jac, n_params, n_params, n_params)
    end
    
    return third_derivs
end


"""
    _compute_subject_third_derivatives(Î², cache::ImplicitBetaCache{M, MPanelData}) -> Vector{Array{Float64,3}}

Compute third derivatives âˆ‚Háµ¢/âˆ‚Î² for all subjects for Markov panel data.
"""
function _compute_subject_third_derivatives(Î²::Vector{Float64}, cache::ImplicitBetaCache{M, MPanelData}) where M
    n_subjects = length(cache.model.subjectindices)
    n_params = length(Î²)
    
    third_derivs = Vector{Array{Float64,3}}(undef, n_subjects)
    
    for i in 1:n_subjects
        # Compute Jacobian of flattened Hessian
        H_flat_jac = ForwardDiff.jacobian(
            b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, i), b)),
            Î²
        )
        # Reshape to tensor: third_derivs[i][:,:,l] = âˆ‚Háµ¢/âˆ‚Î²â‚—
        third_derivs[i] = reshape(H_flat_jac, n_params, n_params, n_params)
    end
    
    return third_derivs
end


"""
    _compute_subject_third_derivatives(Î², cache::ImplicitBetaCache{M, MCEMSelectionData}) -> Vector{Array{Float64,3}}

Compute third derivatives âˆ‚Háµ¢/âˆ‚Î² for all subjects for MCEM data.
"""
function _compute_subject_third_derivatives(Î²::Vector{Float64}, cache::ImplicitBetaCache{M, MCEMSelectionData}) where M
    n_subjects = length(cache.model.subjectindices)
    n_params = length(Î²)
    
    third_derivs = Vector{Array{Float64,3}}(undef, n_subjects)
    
    for i in 1:n_subjects
        # Compute Jacobian of flattened Hessian
        H_flat_jac = ForwardDiff.jacobian(
            b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, i), b)),
            Î²
        )
        # Reshape to tensor: third_derivs[i][:,:,l] = âˆ‚Háµ¢/âˆ‚Î²â‚—
        third_derivs[i] = reshape(H_flat_jac, n_params, n_params, n_params)
    end
    
    return third_derivs
end


# =============================================================================
# JVP-Based Third Derivative Contractions (Phase 4.3 Optimization)
# =============================================================================
# These functions compute Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·vâ‚— without materializing the full pÃ—pÃ—p tensor.
# This reduces memory from O(pÂ³) to O(pÂ²) and computation from O(npÂ³) to O(npÂ²).
# =============================================================================

"""
    _compute_dH_times_v(Î², v, cache::ImplicitBetaCache, subject_idx::Int) -> Matrix{Float64}

Compute the contraction Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·vâ‚— for a single subject using directional derivatives.

This is the directional derivative of Háµ¢(Î²) in direction v, computed as:
    d/dt [Háµ¢(Î² + tÂ·v)]|_{t=0}

# Mathematical Background
The third derivative tensor T[j,k,l] = âˆ‚Â²â„“áµ¢/âˆ‚Î²â±¼âˆ‚Î²â‚–âˆ‚Î²â‚— is symmetric in all indices.
The contraction Î£â‚— T[:,:,l]Â·vâ‚— equals the directional derivative of the Hessian.

# Arguments
- `Î²::Vector{Float64}`: Current parameter estimate
- `v::AbstractVector{Float64}`: Direction vector for contraction
- `cache::ImplicitBetaCache`: Contains model and data
- `subject_idx::Int`: Subject index

# Returns
Matrix{Float64} of size (p, p) containing Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·vâ‚—

# Performance
O(pÂ²) memory and O(pÂ²) computation vs O(pÂ³) for explicit tensor.
"""
function _compute_dH_times_v(
    Î²::Vector{Float64},
    v::AbstractVector{Float64},
    cache::ImplicitBetaCache{M, ExactData},
    subject_idx::Int
) where M
    n_params = length(Î²)
    
    # Directional derivative: d/dt [Háµ¢(Î² + tÂ·v)]|_{t=0}
    # Implemented as: ForwardDiff of the Hessian function at Î², in direction v
    # We use the JVP pattern: pushforward of H at Î² with tangent v
    
    # Compute Hessian function value and its Jacobian applied to v
    # H(Î² + ÎµÂ·v) â‰ˆ H(Î²) + ÎµÂ·(dH/dÎ²)Â·v
    # The (dH/dÎ²)Â·v term is what we want
    
    hess_func = b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, subject_idx), b))
    
    # Use ForwardDiff.Dual to compute directional derivative
    Î²_dual = ForwardDiff.Dual.(Î², v)
    H_flat_dual = hess_func(Î²_dual)
    
    # Extract the derivative part (partials)
    dH_times_v_flat = ForwardDiff.partials.(H_flat_dual, 1)
    
    return reshape(dH_times_v_flat, n_params, n_params)
end

function _compute_dH_times_v(
    Î²::Vector{Float64},
    v::AbstractVector{Float64},
    cache::ImplicitBetaCache{M, MPanelData},
    subject_idx::Int
) where M
    n_params = length(Î²)
    
    hess_func = b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, subject_idx), b))
    
    Î²_dual = ForwardDiff.Dual.(Î², v)
    H_flat_dual = hess_func(Î²_dual)
    dH_times_v_flat = ForwardDiff.partials.(H_flat_dual, 1)
    
    return reshape(dH_times_v_flat, n_params, n_params)
end

function _compute_dH_times_v(
    Î²::Vector{Float64},
    v::AbstractVector{Float64},
    cache::ImplicitBetaCache{M, MCEMSelectionData},
    subject_idx::Int
) where M
    n_params = length(Î²)
    
    hess_func = b -> vec(-ForwardDiff.hessian(bb -> loglik_subject(bb, cache.data, subject_idx), b))
    
    Î²_dual = ForwardDiff.Dual.(Î², v)
    H_flat_dual = hess_func(Î²_dual)
    dH_times_v_flat = ForwardDiff.partials.(H_flat_dual, 1)
    
    return reshape(dH_times_v_flat, n_params, n_params)
end


"""
    _compute_all_dH_times_v(Î², V, cache::ImplicitBetaCache) -> Vector{Vector{Matrix{Float64}}}

Compute contractions Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·V[j,l] for all subjects and all direction vectors.

# Arguments
- `Î²::Vector{Float64}`: Current parameter estimate
- `V::AbstractMatrix{Float64}`: Direction vectors, shape (n_params, n_directions)
- `cache::ImplicitBetaCache`: Contains model and data

# Returns
Vector of length n_subjects, where each element is a Vector of length n_directions,
where each element is a (p, p) matrix: dH_times_v[i][j] = Î£â‚— (âˆ‚Háµ¢/âˆ‚Î²â‚—)Â·V[l,j]
"""
function _compute_all_dH_times_v(
    Î²::Vector{Float64},
    V::AbstractMatrix{Float64},
    cache::ImplicitBetaCache{M, ExactData}
) where M
    n_subjects = length(cache.data.paths)
    n_directions = size(V, 2)
    
    result = Vector{Vector{Matrix{Float64}}}(undef, n_subjects)
    
    for i in 1:n_subjects
        result[i] = Vector{Matrix{Float64}}(undef, n_directions)
        for j in 1:n_directions
            result[i][j] = _compute_dH_times_v(Î², view(V, :, j), cache, i)
        end
    end
    
    return result
end

function _compute_all_dH_times_v(
    Î²::Vector{Float64},
    V::AbstractMatrix{Float64},
    cache::ImplicitBetaCache{M, MPanelData}
) where M
    n_subjects = length(cache.model.subjectindices)
    n_directions = size(V, 2)
    
    result = Vector{Vector{Matrix{Float64}}}(undef, n_subjects)
    
    for i in 1:n_subjects
        result[i] = Vector{Matrix{Float64}}(undef, n_directions)
        for j in 1:n_directions
            result[i][j] = _compute_dH_times_v(Î², view(V, :, j), cache, i)
        end
    end
    
    return result
end

function _compute_all_dH_times_v(
    Î²::Vector{Float64},
    V::AbstractMatrix{Float64},
    cache::ImplicitBetaCache{M, MCEMSelectionData}
) where M
    n_subjects = length(cache.model.subjectindices)
    n_directions = size(V, 2)
    
    result = Vector{Vector{Matrix{Float64}}}(undef, n_subjects)
    
    for i in 1:n_subjects
        result[i] = Vector{Matrix{Float64}}(undef, n_directions)
        for j in 1:n_directions
            result[i][j] = _compute_dH_times_v(Î², view(V, :, j), cache, i)
        end
    end
    
    return result
end





# =============================================================================
# PIJCV with Implicit Differentiation - Main Entry Point
# =============================================================================

"""
    _nested_optimization_pijcv_implicit(model, data::ExactData, penalty, selector; kwargs...) -> HyperparameterSelectionResult

Nested optimization for PIJCV using ImplicitDifferentiation.jl for efficient gradients.

This is the high-performance version of `_nested_optimization_pijcv` that avoids
nested automatic differentiation by using the implicit function theorem:

    âˆ‚Î²Ì‚/âˆ‚Ïâ±¼ = -H_Î»â»Â¹ Â· (Î»â±¼ Sâ±¼ Î²Ì‚)

# Performance Benefits
- Avoids differentiating through the inner optimization
- Reduces computational complexity from O(npÂ³) to O(npÂ²)
- Expected 15-20x speedup and 10x memory reduction

# Algorithm
1. Build ImplicitBetaCache with model, data, penalty
2. Create ImplicitFunction wrapping the inner optimization
3. Define NCV criterion using implicit Î²Ì‚(Ï)
4. Optimize Ï using ForwardDiff with gradients via implicit diff

# Arguments
- `model::MultistateProcess`: Model for likelihood evaluation
- `data::ExactData`: Data container
- `penalty::AbstractPenalty`: Penalty configuration
- `selector::PIJCVSelector`: PIJCV selector

# Keyword Arguments
- `beta_init::Vector{Float64}`: Initial coefficient estimate
- `inner_maxiter::Int=50`: Maximum iterations for inner Î² fitting
- `outer_maxiter::Int=100`: Maximum iterations for outer Ï optimization
- `lambda_tol::Float64=1e-3`: Convergence tolerance for Î»
- `lambda_init::Union{Nothing, Vector{Float64}}`: Warm-start for Î»
- `verbose::Bool=false`: Print progress

# Returns
- `HyperparameterSelectionResult`: Contains optimal Î», warmstart_beta, updated penalty

# See Also
- `_nested_optimization_pijcv`: Legacy version with nested AD
- `make_implicit_beta_function`: Creates the ImplicitFunction

# References
- Wood, S.N. (2024). "On Neighbourhood Cross Validation." arXiv:2404.16490v4
- Blondel et al. (2022). "Efficient and Modular Implicit Differentiation."
"""
function _nested_optimization_pijcv_implicit(
    model::MultistateProcess,
    data::ExactData,
    penalty::AbstractPenalty,
    selector::PIJCVSelector;
    beta_init::Vector{Float64},
    inner_maxiter::Int = 50,
    outer_maxiter::Int = 100,
    lambda_tol::Float64 = 1e-3,
    lambda_init::Union{Nothing, Vector{Float64}} = nothing,
    verbose::Bool = false
)
    # Get bounds and setup
    lb, ub = model.bounds.lb, model.bounds.ub
    n_lambda = n_hyperparameters(penalty)
    n_subjects = length(data.paths)
    n_params = length(beta_init)
    
    # Determine method based on nfolds and use_quadratic
    method = if selector.use_quadratic
        selector.nfolds == 0 ? :pijlcv_implicit : Symbol("pijlcv$(selector.nfolds)_implicit")
    else
        selector.nfolds == 0 ? :pijcv_implicit : Symbol("pijcv$(selector.nfolds)_implicit")
    end
    
    if verbose
        println("Optimizing Î» via PIJCV with ImplicitDifferentiation.jl")
        println("  Method: $method, n_lambda: $n_lambda")
        selector.use_quadratic && println("  Using fast quadratic approximation V_q")
    end
    
    # Build penalty_config for use in criterion
    penalty_config = penalty isa QuadraticPenalty ? penalty : build_penalty_config(model, SplinePenalty())
    
    # Build implicit differentiation cache
    cache = build_implicit_beta_cache(model, data, penalty_config, beta_init;
                                       inner_maxiter=inner_maxiter)
    
    # Create the implicit function for Î²Ì‚(Ï)
    implicit_beta = make_implicit_beta_function(cache)
    
    # Track evaluations
    n_criterion_evals = Ref(0)
    current_beta_ref = Ref(copy(beta_init))
    
    # Build PIJCV evaluation cache for efficient LOO evaluation
    pijcv_cache = if !selector.use_quadratic
        build_pijcv_eval_cache(data)
    else
        nothing
    end
    
    # Pre-compute Float64 quantities that don't need AD
    # These are computed once at the initial Î² and used as constants for the
    # Newton approximation. The gradients w.r.t. Ï come through Î²Ì‚(Ï) via implicit diff
    # and through Î» in the penalized Hessian directly.
    
    # Define criterion AND gradient function using NCV approximation (Wood 2024)
    # Uses simplified gradient with dÎ”/dÏ weighting but ignores third derivatives for speed
    function ncv_criterion_and_gradient(log_lambda_vec)
        n_criterion_evals[] += 1
        
        # Get Î²Ì‚(Ï) via inner optimization (Float64 only)
        log_lambda_float = Float64.(log_lambda_vec)
        lambda_float = exp.(log_lambda_float)
        penalty_current = set_hyperparameters(penalty_config, lambda_float)
        
        # Solve inner problem
        Î²_float = _fit_inner_coefficients(model, data, penalty_current, current_beta_ref[];
                                          lb=lb, ub=ub, maxiter=inner_maxiter)
        current_beta_ref[] = Î²_float
        
        # Compute dÎ²Ì‚/dÏ via ImplicitDifferentiation.jl
        # This uses the IFT: dÎ²Ì‚/dÏâ±¼ = -H_Î»â»Â¹ Â· (Î»â±¼ Sâ±¼ Î²Ì‚)
        # Returns (n_params Ã— n_lambda) matrix
        dbeta_drho = ForwardDiff.jacobian(
            Ï_vec -> implicit_beta(Ï_vec)[1],
            log_lambda_float
        )
        
        # Compute subject gradients and Hessians at Î²Ì‚
        subject_grads_ll, subject_hessians_ll = compute_subject_grads_and_hessians_fast(
            Î²_float, model, data.paths; use_threads=:auto
        )
        
        # Convert to loss convention
        subject_grads = -subject_grads_ll
        subject_hessians = [-H for H in subject_hessians_ll]
        H_unpenalized = sum(subject_hessians)
        
        # Compute criterion AND analytical gradient simultaneously
        # Uses corrected NCV gradient (including dÎ”/dÏ) but ignoring expensive third derivatives
        V, grad_V = compute_pijcv_with_gradient(
            Î²_float,
            log_lambda_float,
            cache;
            subject_grads=subject_grads,
            subject_hessians=subject_hessians,
            H_unpenalized=H_unpenalized,
            dbeta_drho=dbeta_drho
        )
        
        if verbose && n_criterion_evals[] % 5 == 0
            @info "Criterion eval $(n_criterion_evals[]): log(Î»)=$(round.(log_lambda_float, digits=2)), V=$(round(V, digits=3)), ||âˆ‡V||=$(round(norm(grad_V), digits=4))"
        end
        
        return (V, grad_V)
    end
    
    # Wrapper for criterion only (for OptimizationFunction)
    function ncv_criterion_only(log_lambda_vec, _)
        V, _ = ncv_criterion_and_gradient(log_lambda_vec)
        return V
    end
    
    # Wrapper for gradient only (for OptimizationFunction)
    function ncv_gradient_only!(grad_storage, log_lambda_vec, _)
        _, grad_V = ncv_criterion_and_gradient(log_lambda_vec)
        grad_storage .= grad_V
        return nothing
    end
    
    # Adaptive bounds for log(Î»)
    log_lb_scalar, log_ub_scalar = compute_lambda_bounds(n_subjects, n_params)
    log_lb = fill(log_lb_scalar, n_lambda)
    log_ub = fill(log_ub_scalar, n_lambda)
    
    # Initialize Î»: Use lambda_init if provided, otherwise EFS estimate
    current_log_lambda = if !isnothing(lambda_init) && length(lambda_init) >= n_lambda
        if verbose
            println("  Using provided Î» warm-start (skipping EFS)")
        end
        log.(lambda_init[1:n_lambda])
    else
        # Get EFS estimate as warmstart
        if verbose
            println("  Getting EFS initial estimate...")
        end
        efs_result = _nested_optimization_reml(model, data, penalty;
                                               beta_init=beta_init,
                                               inner_maxiter=inner_maxiter,
                                               outer_maxiter=30,
                                               lambda_tol=0.1,
                                               verbose=false)
        current_beta_ref[] = efs_result.warmstart_beta
        log.(efs_result.lambda[1:n_lambda])
    end
    
    # Set up optimization with analytical gradient
    optf = OptimizationFunction(ncv_criterion_only; grad=ncv_gradient_only!)
    prob = OptimizationProblem(optf, current_log_lambda, nothing; lb=log_lb, ub=log_ub)
    
    if verbose
        println("  Using L-BFGS outer optimizer with analytical gradients...")
    end
    
    # Solve with Fminbox L-BFGS
    sol = solve(prob, OptimizationOptimJL.Fminbox(OptimizationOptimJL.LBFGS());
                maxiters=outer_maxiter,
                f_tol=lambda_tol,
                x_tol=lambda_tol)
    
    optimal_log_lambda = sol.u
    best_criterion = sol.objective
    current_beta = current_beta_ref[]
    converged = sol.retcode == ReturnCode.Success || sol.retcode == ReturnCode.MaxIters
    
    if verbose
        lambda_val = exp.(optimal_log_lambda)
        println("  Final: log(Î»)=$(round.(optimal_log_lambda, digits=2)), Î»=$(round.(lambda_val, sigdigits=3)), V=$(round(best_criterion, digits=3))")
        println("  Criterion evaluations: $(n_criterion_evals[])")
        println(converged ? "  Converged successfully" : "  Warning: Optimizer returned $(sol.retcode)")
    end
    
    # Build final results
    optimal_lambda = exp.(optimal_log_lambda)
    optimal_lambda_vec = n_lambda == 1 ? fill(optimal_lambda[1], n_hyperparameters(penalty_config)) : optimal_lambda
    updated_penalty = set_hyperparameters(penalty, optimal_lambda_vec)
    
    # Compute EDF at optimal (lambda, beta)
    edf = compute_edf(current_beta, optimal_lambda_vec, penalty_config, model, data)
    
    return HyperparameterSelectionResult(
        optimal_lambda_vec,
        current_beta,
        updated_penalty,
        best_criterion,
        edf,
        converged,
        method,
        n_criterion_evals[],
        (log_lambda = optimal_log_lambda, retcode = sol.retcode, implicit_diff = true)
    )
end


# =============================================================================
# Markov Panel Data Support
# =============================================================================

"""
    _compute_penalized_hessian_at_beta(Î², Î», cache::ImplicitBetaCache{M, MPanelData}) -> Matrix{Float64}

Compute the penalized Hessian H_Î» for Markov panel data.
"""
function _compute_penalized_hessian_at_beta(Î²::Vector{Float64}, Î»::Vector{Float64}, 
                                            cache::ImplicitBetaCache{M, MPanelData}) where M
    # Get unpenalized Hessian using Markov likelihood
    H_unpenalized = ForwardDiff.hessian(b -> loglik_markov(b, cache.data; neg=true), Î²)
    
    # Add penalty contributions (same as ExactData)
    n = length(Î²)
    H_lambda = copy(H_unpenalized)
    
    penalty = cache.penalty_config
    lambda_idx = 1
    
    for term in penalty.terms
        idx = term.hazard_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    for term in penalty.total_hazard_terms
        for idx_range1 in term.hazard_indices
            for idx_range2 in term.hazard_indices
                H_lambda[idx_range1, idx_range2] .+= Î»[lambda_idx] * term.S
            end
        end
        lambda_idx += 1
    end
    
    for term in penalty.smooth_covariate_terms
        idx = term.param_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    return H_lambda
end

"""
    _compute_subject_grads_hessians(Î², cache::ImplicitBetaCache{M, MPanelData}) -> (grads, hessians)

Compute per-subject gradients and Hessians for Markov panel data.
"""
function _compute_subject_grads_hessians(Î²::Vector{Float64}, cache::ImplicitBetaCache{M, MPanelData}) where M
    books = cache.data.books
    model = cache.model
    
    # Use existing Markov-specific functions
    grads_ll = compute_subject_gradients(Î², model, books)
    hessians_ll = compute_subject_hessians(Î², model, books)
    
    # Convert to loss convention
    grads = -grads_ll
    hessians = [-H for H in hessians_ll]
    
    return grads, hessians
end

"""
    _nested_optimization_pijcv_markov_implicit(model, data::MPanelData, penalty, selector; kwargs...) -> HyperparameterSelectionResult

Nested optimization for PIJCV using ImplicitDifferentiation.jl for Markov panel data.

Uses analytical gradients via `compute_pijcv_with_gradient`, matching the ExactData
pattern for efficiency and correctness.
"""
function _nested_optimization_pijcv_markov_implicit(
    model::MultistateProcess,
    data::MPanelData,
    penalty::AbstractPenalty,
    selector::PIJCVSelector;
    beta_init::Vector{Float64},
    inner_maxiter::Int = 50,
    outer_maxiter::Int = 100,
    lambda_tol::Float64 = 1e-3,
    lambda_init::Union{Nothing, Vector{Float64}} = nothing,
    verbose::Bool = false
)
    # Get bounds and setup
    lb, ub = model.bounds.lb, model.bounds.ub
    n_lambda = n_hyperparameters(penalty)
    n_subjects = length(model.subjectindices)
    n_params = length(beta_init)
    books = data.books
    
    # Determine method
    method = selector.nfolds == 0 ? :pijcv_implicit : Symbol("pijcv$(selector.nfolds)_implicit")
    
    if verbose
        println("Optimizing Î» via PIJCV with ImplicitDifferentiation.jl for Markov panel data")
        println("  Method: $method, n_lambda: $n_lambda, using analytical gradients")
    end
    
    # Build penalty_config
    penalty_config = penalty isa QuadraticPenalty ? penalty : build_penalty_config(model, SplinePenalty())
    
    # Build implicit differentiation cache
    cache = build_implicit_beta_cache(model, data, penalty_config, beta_init;
                                       inner_maxiter=inner_maxiter)
    
    # Create the implicit function for Î²Ì‚(Ï)
    implicit_beta = make_implicit_beta_function(cache)
    
    # Track evaluations
    n_criterion_evals = Ref(0)
    current_beta_ref = Ref(copy(beta_init))
    
    # Define criterion AND gradient function using analytical gradient (Wood 2024 NCV)
    function ncv_criterion_and_gradient(log_lambda_vec)
        n_criterion_evals[] += 1
        
        # Get Î²Ì‚(Ï) via inner optimization (Float64 only)
        log_lambda_float = Float64.(log_lambda_vec)
        lambda_float = exp.(log_lambda_float)
        penalty_current = set_hyperparameters(penalty_config, lambda_float)
        
        # Solve inner problem
        Î²_float = _fit_inner_coefficients(model, data, penalty_current, current_beta_ref[];
                                          lb=lb, ub=ub, maxiter=inner_maxiter)
        current_beta_ref[] = Î²_float
        
        # Compute dÎ²Ì‚/dÏ via ImplicitDifferentiation.jl
        # Returns (n_params Ã— n_lambda) matrix
        dbeta_drho = ForwardDiff.jacobian(
            Ï_vec -> implicit_beta(Ï_vec)[1],
            log_lambda_float
        )
        
        # Compute subject gradients and Hessians at Î²Ì‚
        subject_grads_ll = compute_subject_gradients(Î²_float, model, books)
        subject_hessians_ll = compute_subject_hessians(Î²_float, model, books)
        
        # Convert to loss convention (see sign conventions in this file)
        subject_grads = -subject_grads_ll
        subject_hessians = [-H for H in subject_hessians_ll]
        H_unpenalized = sum(subject_hessians)
        
        # Compute criterion AND analytical gradient simultaneously
        V, grad_V = compute_pijcv_with_gradient(
            Î²_float,
            log_lambda_float,
            cache;
            subject_grads=subject_grads,
            subject_hessians=subject_hessians,
            H_unpenalized=H_unpenalized,
            dbeta_drho=dbeta_drho
        )
        
        if verbose && n_criterion_evals[] % 5 == 0
            @info "Criterion eval $(n_criterion_evals[]): log(Î»)=$(round.(log_lambda_float, digits=2)), V=$(round(V, digits=3)), ||âˆ‡V||=$(round(norm(grad_V), digits=4))"
        end
        
        return (V, grad_V)
    end
    
    # Wrapper for criterion only (for OptimizationFunction)
    function ncv_criterion_only(log_lambda_vec, _)
        V, _ = ncv_criterion_and_gradient(log_lambda_vec)
        return V
    end
    
    # Wrapper for gradient only (for OptimizationFunction)
    function ncv_gradient_only!(grad_storage, log_lambda_vec, _)
        _, grad_V = ncv_criterion_and_gradient(log_lambda_vec)
        grad_storage .= grad_V
        return nothing
    end
    
    # Adaptive bounds for log(Î»)
    log_lb_scalar, log_ub_scalar = compute_lambda_bounds(n_subjects, n_params)
    log_lb = fill(log_lb_scalar, n_lambda)
    log_ub = fill(log_ub_scalar, n_lambda)
    
    # Initialize Î»
    current_log_lambda = if !isnothing(lambda_init) && length(lambda_init) >= n_lambda
        if verbose
            println("  Using provided Î» warm-start")
        end
        log.(lambda_init[1:n_lambda])
    else
        if verbose
            println("  Getting EFS initial estimate...")
        end
        efs_result = _nested_optimization_criterion_markov(model, data, penalty, :efs;
                                               beta_init=beta_init,
                                               inner_maxiter=inner_maxiter,
                                               outer_maxiter=30,
                                               lambda_tol=0.1,
                                               verbose=false)
        current_beta_ref[] = efs_result.warmstart_beta
        log.(efs_result.lambda[1:n_lambda])
    end
    
    # Set up optimization with analytical gradient
    optf = OptimizationFunction(ncv_criterion_only; grad=ncv_gradient_only!)
    prob = OptimizationProblem(optf, current_log_lambda, nothing; lb=log_lb, ub=log_ub)
    
    if verbose
        println("  Using L-BFGS outer optimizer with analytical gradients...")
    end
    
    # Solve with Fminbox L-BFGS
    sol = solve(prob, OptimizationOptimJL.Fminbox(OptimizationOptimJL.LBFGS());
                maxiters=outer_maxiter,
                f_tol=lambda_tol,
                x_tol=lambda_tol)
    
    optimal_log_lambda = sol.u
    best_criterion = sol.objective
    current_beta = current_beta_ref[]
    converged = sol.retcode == ReturnCode.Success || sol.retcode == ReturnCode.MaxIters
    
    if verbose
        lambda_val = exp.(optimal_log_lambda)
        println("  Final: log(Î»)=$(round.(optimal_log_lambda, digits=2)), Î»=$(round.(lambda_val, sigdigits=3)), V=$(round(best_criterion, digits=3))")
        println("  Criterion evaluations: $(n_criterion_evals[])")
    end
    
    # Build final results
    optimal_lambda = exp.(optimal_log_lambda)
    optimal_lambda_vec = n_lambda == 1 ? fill(optimal_lambda[1], n_hyperparameters(penalty_config)) : optimal_lambda
    updated_penalty = set_hyperparameters(penalty, optimal_lambda_vec)
    
    # Compute EDF
    edf = compute_edf_markov(current_beta, optimal_lambda_vec, penalty_config, model, books)
    
    return HyperparameterSelectionResult(
        optimal_lambda_vec,
        current_beta,
        updated_penalty,
        best_criterion,
        edf,
        converged,
        method,
        n_criterion_evals[],
        (log_lambda = optimal_log_lambda, retcode = sol.retcode, implicit_diff = true)
    )
end

# =============================================================================
# MCEM Data Support  
# =============================================================================

"""
    _compute_penalized_hessian_at_beta(Î², Î», cache::ImplicitBetaCache{M, MCEMSelectionData}) -> Matrix{Float64}

Compute the penalized Hessian H_Î» for MCEM data using importance-weighted semi-Markov likelihood.
"""
function _compute_penalized_hessian_at_beta(Î²::Vector{Float64}, Î»::Vector{Float64}, 
                                            cache::ImplicitBetaCache{M, MCEMSelectionData}) where M
    # Create SMPanelData for semi-Markov likelihood
    sm_data = SMPanelData(cache.data.model, cache.data.paths, cache.data.weights)
    
    # Get unpenalized Hessian using importance-weighted semi-Markov likelihood
    H_unpenalized = ForwardDiff.hessian(b -> loglik_semi_markov(b, sm_data; neg=true, use_sampling_weight=true), Î²)
    
    # Add penalty contributions
    n = length(Î²)
    H_lambda = copy(H_unpenalized)
    
    penalty = cache.penalty_config
    lambda_idx = 1
    
    for term in penalty.terms
        idx = term.hazard_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    for term in penalty.total_hazard_terms
        for idx_range1 in term.hazard_indices
            for idx_range2 in term.hazard_indices
                H_lambda[idx_range1, idx_range2] .+= Î»[lambda_idx] * term.S
            end
        end
        lambda_idx += 1
    end
    
    for term in penalty.smooth_covariate_terms
        idx = term.param_indices
        H_lambda[idx, idx] .+= Î»[lambda_idx] * term.S
        lambda_idx += 1
    end
    
    return H_lambda
end

"""
    _compute_subject_grads_hessians(Î², cache::ImplicitBetaCache{M, MCEMSelectionData}) -> (grads, hessians)

Compute per-subject gradients and Hessians for MCEM data using existing importance-weighted functions.
"""
function _compute_subject_grads_hessians(Î²::Vector{Float64}, cache::ImplicitBetaCache{M, MCEMSelectionData}) where M
    # Use the existing importance-weighted gradient/Hessian computation
    model = cache.data.model
    paths = cache.data.paths
    weights = cache.data.weights
    
    grads_ll = compute_subject_gradients(Î², model, paths, weights)
    hessians_ll = compute_subject_hessians(Î², model, paths, weights)
    
    # Convert to loss convention
    grads = -grads_ll
    hessians = [-H for H in hessians_ll]
    
    return grads, hessians
end

"""
    _nested_optimization_pijcv_mcem_implicit(model, data::MCEMSelectionData, penalty, selector; kwargs...) -> HyperparameterSelectionResult

Nested optimization for PIJCV using ImplicitDifferentiation.jl for MCEM data.

Uses analytical gradients via `compute_pijcv_with_gradient`, matching the ExactData
and Markov patterns for efficiency and correctness.
"""
function _nested_optimization_pijcv_mcem_implicit(
    model::MultistateProcess,
    data::MCEMSelectionData,
    penalty::AbstractPenalty,
    selector::PIJCVSelector;
    beta_init::Vector{Float64},
    inner_maxiter::Int = 50,
    outer_maxiter::Int = 100,
    lambda_tol::Float64 = 1e-3,
    verbose::Bool = false
)
    # Get bounds and setup
    lb, ub = model.bounds.lb, model.bounds.ub
    n_lambda = n_hyperparameters(penalty)
    n_subjects = length(data.paths)  # Number of subjects from paths vector
    n_params = length(beta_init)
    
    # Determine method
    method = selector.nfolds == 0 ? :pijcv_implicit : Symbol("pijcv$(selector.nfolds)_implicit")
    
    if verbose
        println("Optimizing Î» via PIJCV with ImplicitDifferentiation.jl for MCEM data")
        println("  Method: $method, n_lambda: $n_lambda, using analytical gradients")
    end
    
    # Build penalty_config
    penalty_config = penalty isa QuadraticPenalty ? penalty : build_penalty_config(model, SplinePenalty())
    
    # Build implicit differentiation cache
    cache = build_implicit_beta_cache(model, data, penalty_config, beta_init;
                                       inner_maxiter=inner_maxiter)
    
    # Create the implicit function for Î²Ì‚(Ï)
    implicit_beta = make_implicit_beta_function(cache)
    
    # Track evaluations
    n_criterion_evals = Ref(0)
    current_beta_ref = Ref(copy(beta_init))
    
    # Define criterion AND gradient function using analytical gradient (Wood 2024 NCV)
    function ncv_criterion_and_gradient(log_lambda_vec)
        n_criterion_evals[] += 1
        
        # Get Î²Ì‚(Ï) via inner optimization (Float64 only)
        log_lambda_float = Float64.(log_lambda_vec)
        lambda_float = exp.(log_lambda_float)
        penalty_current = set_hyperparameters(penalty_config, lambda_float)
        
        # Solve inner problem
        Î²_float = _fit_inner_coefficients(model, data, penalty_current, current_beta_ref[];
                                          lb=lb, ub=ub, maxiter=inner_maxiter)
        current_beta_ref[] = Î²_float
        
        # Compute dÎ²Ì‚/dÏ via ImplicitDifferentiation.jl
        # Returns (n_params Ã— n_lambda) matrix
        dbeta_drho = ForwardDiff.jacobian(
            Ï_vec -> implicit_beta(Ï_vec)[1],
            log_lambda_float
        )
        
        # Compute subject gradients and Hessians at Î²Ì‚ (already in loss convention)
        subject_grads, subject_hessians = _compute_subject_grads_hessians(Î²_float, cache)
        H_unpenalized = sum(subject_hessians)
        
        # Compute criterion AND analytical gradient simultaneously
        V, grad_V = compute_pijcv_with_gradient(
            Î²_float,
            log_lambda_float,
            cache;
            subject_grads=subject_grads,
            subject_hessians=subject_hessians,
            H_unpenalized=H_unpenalized,
            dbeta_drho=dbeta_drho
        )
        
        if verbose && n_criterion_evals[] % 5 == 0
            @info "Criterion eval $(n_criterion_evals[]): log(Î»)=$(round.(log_lambda_float, digits=2)), V=$(round(V, digits=3)), ||âˆ‡V||=$(round(norm(grad_V), digits=4))"
        end
        
        return (V, grad_V)
    end
    
    # Wrapper for criterion only (for OptimizationFunction)
    function ncv_criterion_only(log_lambda_vec, _)
        V, _ = ncv_criterion_and_gradient(log_lambda_vec)
        return V
    end
    
    # Wrapper for gradient only (for OptimizationFunction)
    function ncv_gradient_only!(grad_storage, log_lambda_vec, _)
        _, grad_V = ncv_criterion_and_gradient(log_lambda_vec)
        grad_storage .= grad_V
        return nothing
    end
    
    # Adaptive bounds for log(Î»)
    log_lb_scalar, log_ub_scalar = compute_lambda_bounds(n_subjects, n_params)
    log_lb = fill(log_lb_scalar, n_lambda)
    log_ub = fill(log_ub_scalar, n_lambda)
    
    # Initialize Î» with EFS
    if verbose
        println("  Getting EFS initial estimate...")
    end
    efs_result = _nested_optimization_criterion_mcem(model, data, penalty, :efs;
                                           beta_init=beta_init,
                                           inner_maxiter=inner_maxiter,
                                           outer_maxiter=30,
                                           lambda_tol=0.1,
                                           verbose=false)
    current_beta_ref[] = efs_result.warmstart_beta
    current_log_lambda = log.(efs_result.lambda[1:n_lambda])
    
    # Set up optimization with analytical gradient
    optf = OptimizationFunction(ncv_criterion_only; grad=ncv_gradient_only!)
    prob = OptimizationProblem(optf, current_log_lambda, nothing; lb=log_lb, ub=log_ub)
    
    if verbose
        println("  Using L-BFGS outer optimizer with analytical gradients...")
    end
    
    # Solve with Fminbox L-BFGS
    sol = solve(prob, OptimizationOptimJL.Fminbox(OptimizationOptimJL.LBFGS());
                maxiters=outer_maxiter,
                f_tol=lambda_tol,
                x_tol=lambda_tol)
    
    optimal_log_lambda = sol.u
    best_criterion = sol.objective
    current_beta = current_beta_ref[]
    converged = sol.retcode == ReturnCode.Success || sol.retcode == ReturnCode.MaxIters
    
    if verbose
        lambda_val = exp.(optimal_log_lambda)
        println("  Final: log(Î»)=$(round.(optimal_log_lambda, digits=2)), Î»=$(round.(lambda_val, sigdigits=3)), V=$(round(best_criterion, digits=3))")
        println("  Criterion evaluations: $(n_criterion_evals[])")
    end
    
    # Build final results
    optimal_lambda = exp.(optimal_log_lambda)
    optimal_lambda_vec = n_lambda == 1 ? fill(optimal_lambda[1], n_hyperparameters(penalty_config)) : optimal_lambda
    updated_penalty = set_hyperparameters(penalty, optimal_lambda_vec)
    
    # Compute EDF
    edf_scalar = compute_edf_mcem(current_beta, optimal_lambda_vec, penalty_config, data)
    edf = (total = edf_scalar, per_term = [edf_scalar])
    
    return HyperparameterSelectionResult(
        optimal_lambda_vec,
        current_beta,
        updated_penalty,
        best_criterion,
        edf,
        converged,
        method,
        n_criterion_evals[],
        (log_lambda = optimal_log_lambda, retcode = sol.retcode, implicit_diff = true)
    )
end

