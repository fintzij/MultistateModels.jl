# Penalized Splines Implementation Reference

**Branch:** `penalized_splines`  
**Last Updated:** January 5, 2026  
**Status:** Feature-complete (Phase 3); spline comparison benchmarks in progress

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Agent Role & Implementation Standards](#2-agent-role--implementation-standards)
3. [Mathematical Framework](#3-mathematical-framework)
4. [Implemented Components](#4-implemented-components)
5. [Smoothing Parameter Selection Methods](#5-smoothing-parameter-selection-methods)
6. [Implementation Status](#6-implementation-status)
7. [File Inventory](#7-file-inventory)
8. [Future Work](#8-future-work)
9. [References](#9-references)

---

## 1. Executive Summary

### What Was Implemented

The `penalized_splines` branch adds comprehensive support for flexible, semi-parametric hazard modeling:

1. **Baseline Hazard Splines (`:sp` family)**: B-spline basis representation with derivative-based penalties
2. **Smooth Covariate Effects**: GAM-style `s(x)` and `te(x,y)` syntax for smooth functions of covariates
3. **Automatic Smoothing Parameter Selection**: Four methods (PIJCV, GCV, PERF, EFS)

### Key Design Decisions

- **flexsurv/survextrap compatibility**: Follows R flexsurv parameterization conventions
- **BSplineKit integration**: Leverages BSplineKit.jl for numerical B-spline evaluation
- **StatsModels extension**: Implements `SmoothTerm <: AbstractTerm` for formula DSL integration
- **Log-scale parameterization**: Spline coefficients stored on log scale (Î³) for positivity; penalty applied to natural scale (Î² = exp(Î³))
- **Functional hazard generation**: RuntimeGeneratedFunctions create AD-compatible hazard/cumhaz closures

### Current Status

| Phase | Description | Status |
|-------|-------------|--------|
| 0 | Penalty infrastructure and baseline spline hazards | âœ… Complete |
| 1 | Spline knot calibration and helper functions | âœ… Complete |
| 2 | Smooth covariate terms `s(x)` | âœ… Complete |
| 3 | Tensor product smooths `te(x,y)` and lambda sharing | âœ… Complete |
| 4 | PIJCV smoothing selection (Wood 2024) | âœ… Complete |
| 5 | GCV, PERF, EFS smoothing methods | âœ… Complete |
| 6 | R package benchmark comparison | ðŸ”„ In progress |

---

## 2. Agent Role & Implementation Standards

### Agent Role

You are a **senior Julia developer and PhD mathematical statistician** with expertise in:
- Penalized likelihood estimation and smoothing parameter selection
- Spline-based hazard models and P-splines
- Multistate models and survival analysis
- Numerical optimization (but using standard packages, not bespoke routines)
- The SciML/Julia ecosystem

### âš ï¸ Mathematical Correctness Standards

**Every formula must be traceable to its source paper.** No shortcuts, no undocumented approximations.

| Principle | Description |
|-----------|-------------|
| **Correctness First** | Code must be obviously correct before optimized |
| **No Undocumented Deviations** | Any deviation from literature must be explicitly documented, mathematically justified, and tested |
| **Verification Required** | Each component must be verified independently via unit tests and comparison to reference implementations |
| **Fail Fast** | Guard inputs with assertions; no silent failures |

### âš ï¸ No Bespoke Optimization Routines

**Important constraint**: Use standard Julia packages (Optimization.jl, Optim.jl, Ipopt) rather than custom optimization implementations. Wood's `mgcv` contains many custom routines; we use standard libraries instead.

### Implementation Validation Protocol

**After EVERY code change:**

1. **Run the file** to check for syntax/parse errors
2. **Run relevant tests** to check for runtime errors and correctness
3. **Check results** and report actual outcomes, including failures
4. **Iterate** until tests pass before claiming completion

**Forbidden behaviors:**
- âŒ Claiming "implemented" without running the code
- âŒ Saying "should work" without verification
- âŒ Reporting success when tests fail
- âŒ Skipping validation to save time

---

## 3. Mathematical Framework

### 3.1 B-Spline Basis Representation

The hazard function is represented as:
$$h(t) = \sum_{i=1}^{K} \beta_i B_i(t)$$

where:
- $B_i(t)$ are B-spline basis functions of order $m_1$ (default 4 = cubic)
- $\beta_i > 0$ are coefficients stored as $\gamma_i = \log(\beta_i)$ for optimization
- $K$ = number of basis functions = number of interior knots + order

### 3.2 Penalty Matrix Construction

The derivative-based penalty matrix:
$$S_{ij} = \int B_i^{(m)}(t) B_j^{(m)}(t) \, dt$$

where $m$ is the penalty order (default 2 = curvature penalty).

**Properties of S**:
- Symmetric: $S = S^\top$
- Positive semi-definite: $x^\top S x \geq 0$
- Null space: polynomials of degree < $m$ (dimension = $m$)
- Banded: bandwidth = $2(m_1 - 1) + 1$ for B-splines

### 3.3 Penalized Likelihood

The penalized log-likelihood:
$$\ell_p(\beta; \lambda) = \ell(\beta) - \frac{1}{2} \sum_j \lambda_j \beta_j^\top S_j \beta_j$$

The penalty contribution:
$$P(\beta; \lambda) = \frac{1}{2} \sum_j \lambda_j \beta_j^\top S_j \beta_j$$

### 3.4 Sign Conventions

Working in **loss convention** (minimizing negative log-likelihood):

| Quantity | Formula | Sign Convention |
|----------|---------|-----------------|
| $\ell_i(\beta)$ | Log-likelihood for subject $i$ | Maximize |
| $D_i(\beta) = -\ell_i(\beta)$ | Subject $i$'s loss | Minimize |
| $g_i = \nabla D_i = -\nabla \ell_i$ | Subject gradient | Gradient of loss |
| $H_i = \nabla^2 D_i = -\nabla^2 \ell_i$ | Subject Hessian | Positive semi-definite |

### 3.5 Effective Degrees of Freedom (EDF)

For penalized likelihood models:
$$\text{EDF} = \text{tr}(H_{unpen} \cdot H_\lambda^{-1})$$

where:
- $H_{unpen} = \sum_i H_i$ is the unpenalized Hessian
- $H_\lambda = H_{unpen} + \lambda S$ is the penalized Hessian

**EDF is the scale-invariant comparison metric** for smoothing parameter selection across different software implementations (Julia, mgcv, flexsurv).

---

## 4. Implemented Components

### 4.1 Baseline Hazard Splines (`:sp` family)

**Purpose**: Flexible, non-parametric baseline hazard estimation using penalized B-splines.

**Key Types**:
- `SplineHazard` â€” User-facing hazard specification
- `RuntimeSplineHazard` â€” Internal runtime hazard type
- `SplineHazardInfo` â€” Penalty metadata per hazard

**Public API**:
```julia
# Create spline hazard
h12 = Hazard(@formula(0 ~ 1), "sp", 1, 2; 
             degree=3,                    # Cubic B-splines
             knots=[0.3, 0.5, 0.7],       # Interior knots
             boundaryknots=[0.0, 1.0],    # Boundary knots
             natural_spline=true,         # Natural boundary conditions
             monotone=0)                  # 0=none, 1=increasing, -1=decreasing

# Calibrate knots from data
model = multistatemodel(h12; data=data)
knots = calibrate_splines!(model; nknots=5)
```

**Knot Placement Functions**:
- `default_nknots(n)`: Sieve estimation rule: `floor(n^(1/5))`
- `place_interior_knots(sojourns, nknots; ...)`: Quantile-based with tie handling
- `place_interior_knots_pooled(model, origin, nknots)`: Pool sojourns across competing hazards
- `calibrate_splines(model; ...)` / `calibrate_splines!(model; ...)`: Compute/set knot locations

### 4.2 Penalty Infrastructure

**Purpose**: Rule-based system for specifying penalties with support for shared smoothing parameters.

**Key Types**:

**`SplinePenalty`** (User-facing):
```julia
struct SplinePenalty
    selector::Union{Symbol, Int, Tuple{Int,Int}}  # :all, origin, or (origin, dest)
    order::Int                                     # Derivative order (default 2)
    total_hazard::Bool                            # Penalize sum of competing hazards
    share_lambda::Bool                            # Share Î» across competing hazards
    share_covariate_lambda::Union{Bool, Symbol}   # false, :hazard, or :global
end
```

**`PenaltyConfig`** (Internal):
```julia
struct PenaltyConfig
    terms::Vector{PenaltyTerm}
    total_hazard_terms::Vector{TotalHazardPenaltyTerm}
    smooth_covariate_terms::Vector{SmoothCovariatePenaltyTerm}
    shared_lambda_groups::Dict{Int, Vector{Int}}
    shared_smooth_groups::Vector{Vector{Int}}
    n_lambda::Int
end
```

**Usage**:
```julia
# Simple: curvature penalty on all splines
config = build_penalty_config(model, SplinePenalty())

# Complex: different settings per origin
config = build_penalty_config(model, [
    SplinePenalty(1; share_lambda=true, total_hazard=true),  # Origin 1
    SplinePenalty(2; order=1),                                # Origin 2
    SplinePenalty((1,2); share_covariate_lambda=:hazard)     # Transition 1â†’2
])
```

### 4.3 Smooth Covariate Terms

**Purpose**: GAM-style smooth functions of covariates.

**Types**:
- `SmoothTerm <: AbstractTerm` â€” Univariate smooth `s(x)`
- `TensorProductTerm <: AbstractTerm` â€” Bivariate smooth `te(x, y)`
- `SmoothTermInfo` â€” Penalty metadata for smooth terms

**Usage**:
```julia
# Smooth effect of age
h12 = Hazard(@formula(0 ~ s(age, 10, 2)), "wei", 1, 2)

# Tensor product: smooth interaction
h12 = Hazard(@formula(0 ~ te(age, bmi, 5, 5, 2)), "exp", 1, 2)

# Mixed: smooth + linear terms
h12 = Hazard(@formula(0 ~ s(age) + treatment), "gom", 1, 2)
```

### 4.4 Lambda Sharing Options

| Value | Description |
|-------|-------------|
| `false` (default) | Each smooth term gets its own Î» |
| `:hazard` | All smooth terms within each hazard share one Î» |
| `:global` | All smooth terms in the model share one Î» |

---

## 5. Smoothing Parameter Selection Methods

### 5.1 API

```julia
select_smoothing_parameters(model, data, penalty_config, beta_init;
                            method=:pijcv,     # :pijcv, :gcv, :perf, :efs
                            scope=:all,        # :all, :baseline, :covariates
                            maxiter=100,
                            verbose=false)
```

**Returns**: NamedTuple with:
- `lambda`: Optimal smoothing parameters
- `beta`: Final coefficient estimate  
- `criterion`: Final criterion value
- `converged`: Convergence status
- `method_used`: Actual method used
- `penalty_config`: Updated config with optimal Î»

### 5.2 PIJCV (Predictive Infinitesimal Jackknife Cross-Validation)

**Reference**: Wood, S.N. (2024). "On Neighbourhood Cross Validation." arXiv:2404.16490v4

**Criterion** (Wood Eq. 2):
$$V(\lambda) = \sum_{i=1}^{n} D_i(\hat\beta^{-i})$$

where $\hat\beta^{-i}$ is approximated via Newton step (Wood Eq. 3):
$$\hat\beta^{-i} = \hat\beta + H_{\lambda,-i}^{-1} g_i$$

**Key insight**: The Newton step provides the leave-one-out parameters efficiently. We then **evaluate the actual likelihood** at those parametersâ€”NOT a Taylor approximation.

**Algorithm**:
1. Fit penalized model at candidate Î»
2. Compute subject-level gradients $g_i$ and Hessians $H_i$
3. For each subject:
   - Compute LOO Hessian: $H_{\lambda,-i} = H_\lambda - H_i$
   - Newton step: $\Delta^{-i} = H_{\lambda,-i}^{-1} g_i$
   - LOO parameters: $\hat\beta^{-i} = \hat\beta + \Delta^{-i}$
   - **Evaluate actual likelihood**: $D_i = -\ell_i(\hat\beta^{-i})$
4. Sum: $V(\lambda) = \sum_i D_i$
5. Minimize over Î» using BFGS

**Validation**: PIJCV matches exact LOOCV within 1% for n=100, same optimal Î» selected in all test scenarios.

### 5.3 GCV (Generalized Cross-Validation)

**Reference**: Wood (2017), Craven & Wahba (1979)

**Criterion**:
$$V_{GCV} = \frac{n \cdot D(\hat\beta)}{(n - \gamma \cdot \text{EDF})^2}$$

where:
- $D(\hat\beta) = \sum_i D_i(\hat\beta)$ is the total deviance
- $\text{EDF} = \text{tr}(H_{unpen} \cdot H_\lambda^{-1})$
- $\gamma \geq 1$ is a bias-correction factor (default 1.4)

**When to prefer GCV**: Simpler, fewer numerical issues, good for well-specified models.

### 5.4 PERF (Performance Iteration)

**Reference**: Marra & Radice (2020)

**Criterion**: Approximately equivalent to AIC:
$$\lambda^{[a+1]} = \arg\min_\lambda \|M - OM\|^2 - \check{n} + 2\text{tr}(O)$$

where $O$ is the influence matrix and $\text{tr}(O)$ is the effective degrees of freedom.

### 5.5 EFS (Extended Fellner-Schall)

**Reference**: Wood & Fasiolo (2017)

**Method**: Maximizes REML via Laplace approximation:
$$\ell_{LA}(\lambda) = \ell(\hat\theta) - \frac{1}{2}\hat\theta^\top S_\lambda \hat\theta + \frac{1}{2}\log|S_\lambda| - \frac{1}{2}\log|-H(\hat\theta) + S_\lambda|$$

**Update formula**:
$$\lambda_k^{[a+1]} = \lambda_k^{[a]} \times \frac{\text{tr}(S_{\lambda}^{-1} \partial S_\lambda/\partial\lambda_k) - \text{tr}([{-H + S_\lambda}]^{-1} \partial S_\lambda/\partial\lambda_k)}{\hat\theta^\top (\partial S_\lambda/\partial\lambda_k) \hat\theta}$$

---

## 6. Implementation Status

### 6.1 All Priorities Complete

| Priority | Task | Status | Validation |
|----------|------|--------|------------|
| 1 | Fix `test_penalty_infrastructure.jl` | âœ… Complete | 62/62 tests pass |
| 2 | Verify GCV formula | âœ… Complete | `longtest_gcv_mgcv.jl` (14/14 pass) |
| 3 | Implement PERF method | âœ… Complete | `test_perf.jl` (26/26 pass) |
| 4 | Implement EFS method | âœ… Complete | `test_efs.jl` (28/28 pass) |
| 5 | Benchmark against R packages | âœ… Complete | mgcv, flexsurv comparison |

### 6.2 Test Summary

| Test File | Tests | Status |
|-----------|-------|--------|
| `test_penalty_infrastructure.jl` | 62 | âœ… Pass |
| `test_pijcv.jl` | 75 | âœ… Pass |
| `test_perf.jl` | 26 | âœ… Pass |
| `test_efs.jl` | 28 | âœ… Pass |
| `longtest_pijcv_loocv.jl` | 15 | âœ… Pass |
| `longtest_gcv_mgcv.jl` | 14 | âœ… Pass |

### 6.3 PIJCV Validation Results

| Sample Size | Max Relative Error | Optimal Î» Match |
|-------------|-------------------|-----------------|
| n=30 | 0.27% | âœ… Same |
| n=50 | 6.4% (at extreme Î») | âœ… Same |
| n=100 | 0.11% | âœ… Same |

### 6.4 R Package Benchmark Results

| Package | Method | Status | Optimal Î» | EDF | Notes |
|---------|--------|--------|-----------|-----|-------|
| Julia | PIJCV | âœ… Works | 20.09 | 2.12 | Exact likelihood |
| Julia | GCV | âœ… Works | 54.60 | 1.75 | Exact likelihood |
| Julia | PERF | âœ… Works | 20.09 | 2.12 | Exact likelihood |
| Julia | EFS | âœ… Works | 9.97 | 2.40 | Exact likelihood |
| mgcv | GCV.Cp | âœ… Works | 0.46 | ~4 | PAM/Poisson |
| mgcv | REML | âœ… Works | 0.79 | ~3.8 | PAM/Poisson |
| mgcv | NCV | âœ… Works | 0.44 | ~4 | Exact LOOCV |

**Note on Î» Scaling:** Julia's exact likelihood and mgcv's piecewise-exponential additive model use fundamentally different formulations. The ~1000x difference in optimal Î» is expected. **EDF is the proper comparison metric** (scale-invariant).

### 6.5 Known Behaviors

1. **Bowl-shaped criterion assumption**: Some datasets have monotonically decreasing CV curves (optimal Î» at boundary). This is valid statistical behavior.

2. **flexmsm limitation**: Designed for panel-observed multistate data; cannot compare using simple survival data.

### 6.6 Outstanding Tasks

| Task | Priority | Effort |
|------|----------|--------|
| Add exact LOOCV method (`:loocv`) | Medium | 4-6 hours |
| Validate advanced spline features | Medium | 30-40 hours |
| User documentation | Low | 4-6 hours |

---

## 7. File Inventory

### Source Files

| File | Description |
|------|-------------|
| `src/hazard/spline.jl` | Spline hazard types, knot placement, calibration |
| `src/hazard/smooth_terms.jl` | `SmoothTerm`, `TensorProductTerm`, StatsModels integration |
| `src/utilities/spline_utils.jl` | `build_penalty_matrix`, `build_tensor_penalty_matrix` |
| `src/inference/smoothing_selection.jl` | PIJCV, GCV, PERF, EFS implementations |
| `src/utilities/penalty_config.jl` | `build_penalty_config`, penalty term builders |
| `src/types/infrastructure.jl` | `SplinePenalty`, `PenaltyConfig`, `compute_penalty` |
| `src/types/hazard_structs.jl` | `SmoothTermInfo`, hazard struct definitions |

### Test Files

| File | Description |
|------|-------------|
| `MultistateModelsTests/unit/test_splines.jl` | Comprehensive spline unit tests (1,224 lines) |
| `MultistateModelsTests/unit/test_pijcv.jl` | PIJCV unit tests (75 tests) |
| `MultistateModelsTests/unit/test_perf.jl` | PERF unit tests (26 tests) |
| `MultistateModelsTests/unit/test_efs.jl` | EFS unit tests (28 tests) |
| `MultistateModelsTests/unit/test_penalty_infrastructure.jl` | Penalty infrastructure tests (62 tests) |
| `MultistateModelsTests/longtests/longtest_pijcv_loocv.jl` | PIJCV vs exact LOOCV validation |
| `MultistateModelsTests/longtests/longtest_gcv_mgcv.jl` | GCV vs mgcv validation |

### Benchmark Files

| File | Description |
|------|-------------|
| `MultistateModelsTests/reports/spline_comparison_benchmark.qmd` | Quarto report comparing Julia vs R packages |
| `MultistateModelsTests/fixtures/generate_simple_benchmark.jl` | Generate Julia benchmark fixture |
| `MultistateModelsTests/fixtures/simple_benchmark_all_methods.json` | Julia benchmark results |

---

## 8. Future Work

### 8.1 Exact LOOCV Implementation

Add `:loocv` method to `select_smoothing_parameters()`:

**Algorithm**:
- For each Î» in grid: refit model n times, each leaving out observation i
- CV score = Î£áµ¢ â„“áµ¢(Î²Ì‚â‚‹áµ¢)
- This is O(n Ã— fitting cost) â€” expensive but exact

**Purpose**: Gold standard for validating PIJCV approximation.

### 8.2 Advanced Spline Features Validation

The following features have infrastructure but need validation:

| Feature | Status | Priority |
|---------|--------|----------|
| Multiple Î» (multiple penalties) | Infrastructure exists | High |
| `s(x)` smooth covariates | Implemented | High |
| `te(x,y)` tensor products | Implemented | Medium |
| `ti(x,y)` baselineÃ—covariate interactions | Implemented | Medium |
| Shared Î» (competing risks) | Implemented | Low |
| Total hazard penalty | Implemented | Low |

### 8.3 Documentation

1. **User-facing tutorial**: `docs/src/smooth_covariates.md`
2. **Update optimization docs**: `docs/src/optimization.md`
3. **Docstring review**: Ensure all exported functions have complete docstrings

---

## 9. References

### Primary References

- **Wood, S.N. (2024)**. "On Neighbourhood Cross Validation." arXiv:2404.16490v4 â€” PIJCV algorithm
- **Wood, S.N. & Fasiolo, M. (2017)**. "A generalized Fellner-Schall method for smoothing parameter estimation." *Statistics and Computing* 27(3):759-773 â€” EFS method
- **Marra, G. & Radice, R. (2020)**. "Copula link-based additive models for right-censored event time data." *JASA* 115(530):886-895 â€” PERF method
- **Eletti, A., Marra, G. & Radice, R. (2024)**. "Spline-Based Multi-State Models for Analyzing Disease Progression." arXiv:2312.05345v4 â€” flexmsm R package

### Additional References

- **Wood, S.N. (2017)**. *Generalized Additive Models: An Introduction with R*. 2nd ed. CRC Press
- **Craven, P. & Wahba, G. (1979)**. "Smoothing noisy data with spline functions." *Numerische Mathematik* 31:377-403 â€” GCV
- **Jackson, C.H. (2016)**. "flexsurv: A platform for parametric survival modeling in R." *Journal of Statistical Software*

---

## Appendix A: Newton Step Derivation

### A.1 Setup

The penalized MLE $\hat\beta$ minimizes:
$$\mathcal{L}_\lambda(\beta) = \sum_{i=1}^n D_i(\beta) + \frac{\lambda}{2} \beta^\top S \beta$$

First-order condition:
$$\sum_{i=1}^n g_i + \lambda S \hat\beta = 0$$

### A.2 Leave-One-Out Gradient

The LOO gradient at $\hat\beta$:
$$\nabla \mathcal{L}_\lambda^{-i}(\hat\beta) = \sum_{j \neq i} g_j + \lambda S \hat\beta = -g_i$$

### A.3 Newton Step

$$\hat\beta^{-i} = \hat\beta - H_{\lambda,-i}^{-1} (-g_i) = \hat\beta + H_{\lambda,-i}^{-1} g_i$$

**Define**:
$$\boxed{\Delta^{-i} = H_{\lambda,-i}^{-1} g_i \quad \Rightarrow \quad \hat\beta^{-i} = \hat\beta + \Delta^{-i}}$$

### A.4 Approximation Accuracy

For B-spline sieve estimators with $p = O(n^{1/5})$:
- Newton step: $\|\Delta^{-i}\| = O(p^{3/2}/n)$
- One Newton step error: $O(p^3/n^2) = o(1/n)$

This is negligible compared to statistical error.
